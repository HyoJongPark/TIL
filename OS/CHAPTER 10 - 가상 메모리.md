# CHAPTER 10 - 가상 메모리

9장의 메모리 관리 전략들은 모두 다중 프로그래밍을 실현하기 위해 메모리에 많은 프로세스를 동시에 유지하는 것을 목적으로 했다. 

그러나 이 전략에서 접근 방식은 프로세스 전체가 실행되기 전에 메모리로 올라와야 한다는 것을 전제로 한다.

**가상 메모리(virtual memory)**라는 것은 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법이다. 이 기법의 장점은 사용자 프로그램이 물리 메모리보다 커져도 된다는 점이다.

즉, 이 기법을 통해 프로그래머는 메모리의 크기에 제약으로부터 자유로워진다. 또한 가상 메모리는 파일과 라이브러리의 공유를 쉽게 해주고 공유 메모리 구현을 가능하게 해준다.

단점은 구현하기 어렵고, 잘못 사용하게 되면 성능이 현저히 저하될 수 있다.

## 1. 배경_Background

- 실행 중인 코드는 반드시 물리 메모리에 있어야 한다는 조건은 필요하고 타당한 요구조건으로 보이지만, 프로그램의 크기를 물리 메모리의 크기로 제한한다는 점 때문에 환영할만한 조건이 아니다.
- 다음 예시들을 생각해보면 프로그램 전체가 꼭 메모리에 올라와 있어야 하는 것은 아니라는 것을 알 수 있다.
    - 프로그램에는 잘 발생하지 않는 예외처리 코드가 종종 존재한다. 이런 오류들은 실질적으로 거의 발생하지 않으므로, 이 코드들은 잘 실행되지 않는다.
    - 배열, 리스트, 테이블 등은 필요 이상으로 많은 공간을 점유할 수 있다.
    - 프로그램 내의 어떤 옵션이나 기능들은 거의 사용되지 않는다.
- 만약 프로그램의 일부분만 올려놓고 실행할 수 있다면, 다음과 같은 이점을 얻을 수 있다.
    - **프로그램은 물리 메모리 크기에 제약을 받지 않게 된다.** 사용자들은 매우 큰 가상 주소 공간을 가정하고 프로그램을 만들 수 있으므로, 프로그래밍 작업이 간단해진다.
    - 각 프로그램이 더 작은 메모리를 차지해 **더 많은 프로그램이 동시에 실행될 수 있다.** 이에 따라 응답시간은 늘어나지 않으면서 CPU 이용률과 처리율이 높아진다.
    - 프로그램을 메모리에 올리고 스왑하는데 필요한 I/O 회수가 줄어들기 떄문에 **프로그램들이 보다 빨리 실행된다.**
- **가상 메모리**는 실제의 물리 메모리 개념과 개발자의 논리 메모리 개념을 분리한 것으로, 작은 메모리를 가지고도 얼마든지 큰 가상 주소 공간을 프로그래머에게 제공할 수 있다.

---

## 2. 요구 페이징_Demand Paging

프로그램을 보조저장장치에서 메모리로 적재하는 한 가지 방법은 프로그램 실행 시 프로그램의 전부를 메모리에 저장하는 것이다.

이 방법의 문제는 초기에는 프로그램의 전체가 메모리에 있을 필요는 없을지도 모른다는 점이다.

다른 전략은 필요한 페이지만 적재하는 것이다. 이것은 **요구 페이징(demand paging)**이라 하며, 가상 메모리 시스템에서 일반적으로 사용된다.

요구 페이징 가상 메모리를 사용하면, 프로그램 실행 중 필요할 때만 페이지가 적재된다.

### 2.1 기본 개념_Basic Concepts

![Untitled](https://user-images.githubusercontent.com/75190035/177458399-5bb4eca6-cdcc-4b32-af77-ce3c05d8314b.png)

- 요구 페이징을 구현하기 위해 **유효-무효비트 기법**이 사용된다.
    - **비트가 유효**하다고 설정되면, 해당 페이지가 메모리에 있다는 것을 의미한다.
    - **비트가 무효**하다고 설정되면 해당 페이지가 유효하지 않거나, 유효하지만 보조저장장치에 존재한다는 것을 의미한다.
- 프로세스가 메모리에 올라와 있지 않은 페이지에 접근하려고 하면, 테이블 항목이 **무효**로 설정되어 있으므로 **페이지 폴트 트랩**을 발생시킨다.
- **순수 요구 페이징(pure demand paging)**
    - 극단적인 경우에 메모리에 페이지가 하나도 올라와있지 않은 상황에서 프로세스를 실행시킬 수 있다.
    - 운영체제에서 명령 포인터의 값을 프로세스의 첫 명령으로 설정하는 순간, 메모리에 존재하지 않는 페이지에 있으므로 페이지 폴트를 발생시킨다.
    - 페이지가 적재되고 난 후 실행을 계속하는데 프로세스가 사용하는 모든 페이지가 메모리에 올라올 때까지 필요할 때마다 페이지 폴트가 발생한다.
    - 이것이 **순수 요구 페이징**이고, **어떤 페이지가 필요해지기 전에는 결코 그 페이지를 적재하지 않는 방법이다.**
- 프로그램들은 한 명령어에서도 여러 개의 페이지 폴트가 발생할 수 있다. 이렇게 되면 시스템 성능의 저하를 초래한다.
- 다만, 모든 프로그램은 **참조의 지역성(locality of reference)**이라는 성질이 있어 어느 한 특정 작은 부분만 집중적으로 참조하는데, 이러한 성질 때문에 요구 페이징은 만족할 만한 성능을 보인다.
- 요구 페이징을 지원하기 위한 하드웨어
    - 페이지 테이블: 유효/무효 비트를 통해 특정 항목을 무효로 설정할 수 있어야 한다.
    - 보조저장장치: 메인 메모리에 없는 모든 페이지를 가지고 있다. 보통은 고성능의 디스크 또는 NVM 장치다.

### 2.2 요구 페이징의 성능_Performance of Demand Paging

- 요구 페이징은 컴퓨터 시스템의 성능에 큰 영향을 줄 수 있다.
- **실질 접근 시간**
    - 페이지 폴트가 없는 한 실질 접근 시간은 메모리 접근 시간과 같다. 그러나 페이지 폴트가 발생하면, 먼저 보조저장장치에서 해당 페이지를 읽은 다음 원하는 워드에 접근해야 한다.
    - 실질 접근시간 = (1-p) * ma + p * 페이지 폴트 시간
        - p = 페이지 폴트 확률, ma = 메모리 접근 시간
- **실질 접근 시간은 페이지 폴트율에 비례**하며, 페이지 폴트 처리 시간은 크게 3 가지로 이루어 진다.
    1. 인터럽트의 처리
    2. 페이지 읽기
    3. 프로세스 재시작
- 요구 페이징의 또 다른 특성 중 하나는 스왑 공간의 관리이다.
- 시스템이 더 나은 처리량을 얻는 옵션 중 첫번째는 프로세스 시작 시 전체 파일 이미지를 스왑 공간에 복사한 다음 스왑 공간에서 요구 페이징을 수행하는 것이다. 이 방법은 프로그램 시작 시 파일 이미지를 복사하는 단점이 있다.
- 시스템이 더 나은 처리량을 얻는 옵션 중 두 번째 방법은 프로그램을 처음 시작시킬 때에는 파일 시스템으로부터 요구 페이징을 처리하지만, 그 페이지들이 교체될 떄는 스왑 공간에 페이지를 기록하는 것이다.
- 두 번째 방법은 파일 시스템으로부터는 꼭 필요한 페이지들만 읽어 오면서, 그 페이지를 다시 읽어올 때는 스왑 공간에서 읽어온다는 것을 보장한다.

> 실질 접근 시간을 계산하기 위해 페이지 폴트를 처리하는 데 얼마나 많은 시간이 걸리는지 알아야 한다. 페이지 폴트는 다음 순서로 처리된다.
> 
> 1. 운영체제에 트랩을 요청한다.
> 2. 레지스터들과 프로세스 상태를 저장한다.
> 3. 인터럽트 원인이 페이지 폴트임을 알아낸다.
> 4. 페이지 참조가 유효한 것인지 확인하고, 보조저장장치에 있는 페이지의 위치를 알아낸다.
> 5. 저장장치에 가용 프레임으로의 읽기 요구를 낸다.
>     1. 읽기 차례가 돌아오기까지 대기 큐에서 기다린다.
>     2. 디스크에서 찾는 시간과 회전 지연 시간동안 기다린다.
>     3. 가용 프레임으로 페이지 전송을 시작한다.
> 6. 기다리는 동안 CPU 코어는 다른 사용자에게 할당된다.
> 7. 저장장치가 다 읽었다고 인터럽트를 건다.(I/O 완료)
> 8. 다른 프로세스의 레지스터들과 프로세스 상태를 저장한다.(6단계가 실행되었을 경우)
> 9. 인터럽트가 보조저장장치로부터 왔다는 것을 알아낸다.
> 10. 새 페이지가 메모리로 올라왔다는 것을 페이지 테이블과 다른 테이블들에 기록한다.
> 11. CPU 코어가 자기 차례로 오기까지 기다린다.
> 12. CPU 차례가 오면 위에서 저장시켜두었던 레지스터, 프로세스 상태, 새로운 페이지 테이블을 복원시키고 인터럽트되었던 명령어를 다시 실행한다.

---

## 3. 쓰기 시 복사_Copy-on-Write

![Untitled 1](https://user-images.githubusercontent.com/75190035/177458416-2fab74c2-4ed6-469a-9450-2842b832ac55.png)

`fork()` 시스템 콜을 통해 프로세스를 생성할 때는 페이지 공유와 비슷한 기법으로 첫 요구 페이징조차 생략하는 것이 가능하다.

- `fork()` 를 하면 부모 프로세스의 페이지들을 실제로 자식 프로세스에 복사해 줌으로써 자식 프로세스의 주소 공간을 구성해 준다.
- 하지만 대부분의 자식은 이후 `exec()` 시스템 콜을 한다. 그러면 부모로부터 복사해온 페이지들은 다 쓸모없는 것들이 된다.
- 부모의 페이지들을 다 복사해오는 대신 **쓰기 시 복사(copy-on-write) 방식**을 사용할 수 있다.
- 이 방식에서는 자식 프로세스가 시작할 때 부모의 페이지를 당분간 함께 사용하도록 한다. 이때 공유되는 페이지를 쓰기 시 복사 페이지라고 표시한다.
- 둘 중 한 프로세스가 공유 중인 페이지에 쓸 때 그 페이지의 복사본이 만들어진다.
- 수정되지 않는 페이지들은 부모, 자식 간에 계속 공유될 수 있다.
- 쓰기 시 복사 시에는 자식이 부모 주소 공간의 페이지에 변경을 가하지 않도록 주의해야 한다.

---

## 4. 페이지 교체_Page Replacement

### 4.1 기본적인 페이지 교체_Basic Page Replacement

<img width="430" alt="Untitled 2" src="https://user-images.githubusercontent.com/75190035/177458421-c4324fd0-902e-4ec4-a984-a1373718a11c.png">

- 페이지 교체를 포함한 페이지 폴트 서비스 루틴은 다음과 같다.
    1. 보조저장장치에서 필요한 페이지의 위치를 알아낸다.
    2. 빈 페이지 프레임을 찾는다.
        1. 비어 있는 프레임이 있다면 그것을 사용한다.
        2. 비어 있는 프레임이 없다면 **희생될(victim) 프레임을 선정**하기 위해 페이지 교체 알고리즘을 가동시킨다.
        3. 희생될 페이지를 보조저장장치에 기록(필요한 경우), 관련 테이블을 수정해야 한다.
    3. 빼앗은 프레임에 새 페이지를 읽어오고 테이블을 수정한다.
    4. 페이지 폴트가 발생한 지점에서부터 프로세스를 계속한다.
- 빈 프레임이 없는 경우에는 디스크에 두 번 접근해야하므로 페이지 폴트 처리 시간이 2배 소요며, 그에 따라 실질 접근 시간도 증가한다.
    - 한 번은 프레임을 비울 때, 다른 한 번은 읽어 들일 때
- 이러한 오버헤드는 변경 비트를 사용해서 감소시킬 수 있다.
    - 변경 비트는 CPU가 페이지 내의 어떤 바이트라도 쓰게 되면 페이지가 변경되었음을 나타내기 위해 설정된다.
    - 희생시킬 페이지가 선정되면 변경 비트를 확인한다. 이때 변경 비트가 설정되어 있으면 페이지 내용이 변경되었음을 알 수 있다.
- 요구 페이징 시스템은 두 가지 중요한 문제를 해결해야 하는데, **프레임 할당 알고리즘**과 **페이지 교체 알고리즘**이다.
- 즉, 여러 프로세서가 존재하는 경우 각 프로세스에 얼마나 많은 프레임을 할당해야 하는지 결정해야 한다.

> **참조열(reference string)**
> 
> 
> 페이지 교체 알고리즘의 성능은 특정 메모리 참조 나열에 대해 알고리즘을 적용해 페이지 폴트 발생 횟수를 계산해 평가한다. 이러한 메모리 주소 나열을 **참조열**이라 한다.
> 
> 다음과 같은 주소 열에서
> 
> ```python
> 0100, 0432, 0101, 0612, 0102, 0103, 0104, 0101, 0611, 0102, 0103,
> 0104, 0101, 0610, 0102, 0103, 0104, 0101, 0609, 0102, 0105
> ```
> 
> 페이지 크기가 100 바이트라면, 이 열은 다음과 같은 참조열로 줄일 수 있다.
> 
> ```python
> 1, 4, 1, 6, 1, 6, 1, 6, 1
> ```
> 
> 페이지 크기가 주어졌을 때, 주소 전체를 고려하기보다 페이지 번호만 고려하면 된다.
> 
> 페이지 p에 대한 참조가 발생하면, 직후에 p에 접근하는 모든 참조는 페이지 폴트를 발생시키지 않는다. 따라서 다음과 같은 결과를 얻은 것이다.
> 
> 가용 프레임 수와 페이지 폴트의 상관관계는 다음과 같다.
> 
> <img width="460" alt="Untitled 3" src="https://user-images.githubusercontent.com/75190035/177458457-f6a78289-bcac-46cd-beda-559987ee86b6.png">
> 

### 4.2 FIFO 페이지 교체_FIFO Page Replacement

- 가장 간단한 페이지 교체 알고리즘이다.
- FIFO 알고리즘은 어떤 페이지를 교체해야 할 때, 그 희생량(victim)으로 올라온지 가장 오래된 페이지를 선택한다.
- 페이지가 올라온 시간을 페이지마다 기록해도 되고, 페이지들이 올라온 순서대로 큐(FIFO queue)를 가지고 있어도 된다.

**예시 1.**

다음과 같은 참조열이 있고, 3개의 프레임을 갖는 시스템이 있다고 가정하자

```python
7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1
```

처음 3개의 참조(7, 0, 1)는 페이지 폴트를 발생시키고 빈 프레임에 적재된다. 이후 7 → 0 → 1 순서로 희생량으로 선택될 것이다. 결국 총 15개의 페이지 폴트가 발생하며, 전체 결과는 다음과 같다.

<img width="496" alt="Untitled 4" src="https://user-images.githubusercontent.com/75190035/177458468-1d041013-5ef0-4dde-9405-bb3342bb42a2.png">

- FIFO 페이지 교체 알고리즘은 이해하기도 쉽고, 프로그램하기도 쉽다. 그러나 성능이 항상 좋지는 않다.
- 교체된 페이지가 활발하게 사용되고 있는 페이지일 경우 정상적으로 동작 하겠지만, 교체된 이후 거의 즉시 그 페이지를 다시 적재하기 위해 페이지 폴트가 발생할 것이다.
- **잘못된 교체 결정을 페이지 폴트율을 높이고 프로세스 실행 속도를 떨어뜨린다.**

**예시 2.**

한 시스템이 다음과 같은 참조열을 갖는다고 가정하자.

```python
1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5
```

프레임 개수 별 페이지 폴트 횟수는 다음과 같다.

<img width="394" alt="Untitled 5" src="https://user-images.githubusercontent.com/75190035/177458471-2b54ba51-f931-4cdc-a8da-a1aa3a5fe90d.png">

- 결과에서 프레임이 4개인 경우가 3개인 경우보다 페이지 폴트 횟수가 더 많다.
- 이전에 프레임 개수가 페이지 폴트 횟수와 반비례한다는 점과 상반된 결과다. 즉, 상식 밖의 결과다.
- 이런 현상을 **Belady의 모순(Belady’s anomaly)**이라고 부른다.
- Belay의 모순은 프로세스에 더 많은 프레임을 주었는데 오히려 페이지 폴트율은 더 증가하는 현상을 일컫는다.

### 4.3 최적 페이지 교체_Optimal Page Replacement

- 최적 교체 정책이란 모든 알고리즘보다 낮은 페이지 폴트율을 보이며, Belady의 모순이 발생하지 않는 것이다.
- 최적 교체 알고리즘에서는 앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체한다.
- 이 알고리즘은 할당된 프레임 수가 고정된 경우 가장 낮은 페이지 폴트율을 보장한다.

**예시.**

다음과 같은 참조열이 있고, 3개의 프레임을 갖는 시스템이 있다고 가정하자

```python
7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1
```

처음 3개가 적재된 후, 가장 오랫동안 사용되지 않을 순서로 희생량이된다. (7 → 1 → …)

이 알고리즘에서 페이지 폴트는 9번 발생했으며, 결과는 다음과 같다.

<img width="498" alt="Untitled 6" src="https://user-images.githubusercontent.com/75190035/177458481-23a62028-b8b1-47ad-abf7-4832e01ebe9d.png">

- 이 방식은 프로세스가 앞으로 메모리를 어떻게 참조해야하는지 미리 알아야하기 때문에 실제 구현은 어렵다.

### 4.4 LRU 페이지 교체_LRU Page Replacement

- 최적 알고리즘이 거의 불가능하기 때문에, 대신 최적 알고리즘의 근사 알고리즘을 사용한다.
- LRU 알고리즘에서는 **사용될** 시간이 아닌 가장 오랜 시간동안 **사용되지 않은** 페이지를 교체한다.
    - 미래 시간 대신 과거 시간에 대해 적용한 최적 교체 정책
- 따라서, LRU 알고리즘에서는 페이지마다 마지막 사용 시간을 유지한다.
- 구현 방법
    - **계수기(counters)**
        - 가장 간단한 구현 방법으로, **각 페이지 항목마다 사용 시간 필드를 넣는 것**이고, CPU에 논리적인 시계나 계수기를 추가한다.
        - 시간 값이 가장 작은 페이지가 교체된다.
        - 이 기법에서는 LRU 페이지를 찾기 위해 페이지 테이블을 탐색해야 하며, 메모리 참조 때마다 메모리 쓰기 작업을 필요로 한다.
    - 스택(stack)
        - **페이지 번호의 스택을 유지하는 방법이다.**
        - 페이지가 참조될 때마다 페이지 번호는 스택 중간에서 제거되어 스택 꼭대기에 놓이게 된다.
        - 결론적으로 바닥(bottom)에는 가장 오랫동안 사용되지 않은 페이지 번호가, 꼭대기(top)에는 가장 최근에 사용된 페이지 번호가 위치하게 된다.
        - 스택 중간에서 항목을 제거해야 할 필요가 있으므로 보통 doubly linked list로 구현된다.
- 계수기 값과 스택을 갱신하는 일이 메모리 참조 때마다 수행되어야 한다.
- 이러한 작업을 소프트웨어로 하기 위해 인터럽트를 사용하면 메모리 참조 속도가 느려지고, 결국 모든 프로세스의 실행 속도를 그만큼 저하시키게 된다.

**예시.**

다음과 같은 참조열이 있고, 3개의 프레임을 갖는 시스템이 있다고 가정하자.

```python
7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1
```

처음 3개가 적재된 후, 가장 오랫동안 사용되지 않은 순서로 희생량이된다. (7 → 1 → 2 → …)

이 알고리즘에서 페이지 폴트는 12번 발생했으며, 결과는 다음과 같다.

<img width="493" alt="Untitled 7" src="https://user-images.githubusercontent.com/75190035/177458486-2bc9e702-7dd8-441d-af8d-52ceae12ef59.png">

### 4.5 LRU 근사 페이지 교체_LRU Approximation Page Replacement

- LRU 페이지 교체 지원을 충분히 할 수 있는 하드웨어는 많지 않다.
- 많은 시스템은 참조 비트(reference bit)의 형태로 어느 정도의 지원은 하고 있다.
- 페이지 참조가 있을 때마다 하드웨어가 그 페이지에 대한 참조 비트를 설정한다. 참조 비트는 페이지 테이블에 있는 각 항목과 대응된다.
- 처음에 모든 참조 비트는 운영체제에 의해 0으로 채워지고, 이후 참조되는 페이지의 비트는 하드웨어가 1로 세팅한다.
- 사용 순서는 모르지만, 어떤 페이지가 그동안 사용되었고, 한 번도 사용되지 않았는지는 알 수 있고, 이 정보가 많은 LRU 근사 알고리즘의 기본이 된다.

**4.5.1 부가적 참조 비트 알고리즘_Additional-Refrence Bits Alogrithm**

- 일정한 간격마다 참조 비트들을 기록함으로써 추가적인 선후 관계 정보를 얻을 수 있다.
- 각 페이지에 대해 8비트의 참조 비트를 할당하고, 일정 시간마다 타이머 인터럽트를 걸어 참조 비트를 정보의 최상위 비트로 이동시키고, 나머지 비트들은 하나씩 오른쪽으로 이동시킨다.
- 예) 00000000은 한 번도 사용되지 않은 페이지, 10000000은 01111111 보다 더 최근에 사용된 페이지다.

**4.5.2 2차 기회 알고리즘_Second-Chance Algorithm**

<img width="431" alt="Untitled 8" src="https://user-images.githubusercontent.com/75190035/177458491-de5da6b0-6e02-4a59-a7d9-8bc14f7cb3dc.png">

- 2차 기회 알고리즘의 기본은 FIFO 교체 알고리즘이다. 그러나 페이지가 선택될 때마다 참조 비트를 확인한다.
- 참조 비트가 0이면 페이지를 교체하고 1이면 다시 한번 기회를 주고 다음 FIFO페이지로 넘어간다.
- 따라서, 참조 비트가 계속 설정되어 있을 정도로 자주 사용되는 페이지는 전혀 교체되지 않을 것이다.

**4.5.3 개선된 2차 기회 알고리즘_Enhanced Second-Chance Algorithm**

- 2차 기회 알고리즘에서 변경 비트를 조합한 알고리즘이다. 두 개의 비트를 조합해 다음 4가지 등급을 나타낼 수 있다.
1. (0, 0) : 최근에 사용되지도, 변경되지도 않은 경우 - 교체하기 가장 좋은 페이지
2. (0, 1) : 최근에 사용되지는 않았지만, 변경은 된 경우 - 이 페이지를 희생량으로 선택하면, 디스크에 수정 내용을 기록해야 하므로 희생량으로 적절하지 않다.
3. (1, 0) : 최근에 사용은 되었으나 변경은 되지 않은 경우 - 이 페이지는 곧 다시 사용될 가능성이 높다.
4. (1, 1) : 최근에 사용 되었고, 변경도 된 경우 - 아마 곧 다시 사용될 것이며, 희생량으로 적절하지도 않다.
- 페이지 교체가 필요할 때는 참조 비트를 확인하는 것이 아닌, 어떤 등급에 속하는지 확인한다. 그중 가장 낮은 등급을 가지면서 처음 만난 페이지를 교체한다.
- 교체될 페이지를 찾기까지 순환 큐를 여러번 검사할 수 있다.

### 4.6 계수-기반 페이지 교체_Counting-Based Page Replacement

- **LFU 알고리즘(Least Frequently Used Algorithm)**
    - 참조 횟수가 가장 적은 페이지를 교체하는 방법이다.
    - 이 알고리즘은 어떤 프로세스가 초기에만 한 페이지를 집중적으로 사용하다 이후 사용하지 않게되면 판단이 빗나갈 수 있다.
    - 집중적으로 사용됨으로 인해 참조 횟수가 커지고 이후 사용하지 않더라도 계속 메모리에 머물 것이다.
- **MFU 알고리즘(Most Frequently Used)**
    - 가장 작은 참조 회수를 가진 페이지가 가장 최근에 참조된 것이라고 판단하고, 참조 회수가 가장 큰 페이지를 교체한다.
    

### 4.7 페이지-버퍼링 알고리즘_Page-Buffering Algorithm

- 페이지 교체 알고리즘과 병행하여 여러 가지 버퍼링 기법이 사용될 수 있다.
    1. 시스템들이 가용 프레임 여러 개를 풀로 가지고 있다가, 페이지 폴트가 발생하면 예전과 마찬가지로 교체될 페이지를 찾지만, 교체될 페이지의 내용을 디스크에 기록하기 전 가용 프레임에 새로운 페이지를 먼저 읽어 들이는 방법.
        1. 교체될 페이지가 쓰이기를 기다리지 않고 프로세스가 가능한 빨리 시작할 수 있도록 해준다.
        2. 교체될 페이지가 다 쓰이면, 그 프레임이 가용 프레임 풀에 추가된다.
    2. 가용 프레임 풀을 유지하지만 그 속에 각 프레임의 원래 임자 페이지가 누구였는지 기억하는 방법.
        1. 풀 속의 프레임 내용은 그것을 보조장치에 썼다고 하더라도 수정되지 않았을 확률이 있으므로 거기에 저장되어 있던 페이지는 프레임이 사용되기 전까지는 다시 사용될 수 있기 때문이다.

---

## 5. 프레임의 할당_Allocation of Frames

### 5.1 최소로 할당해야 할 프레임의 수_Minimum Number of Frames

- 메모리 할당에는 다양한 제한이 존재한다. 페이지 공유가 없다면 가용 프레임 수보다 더 많이 할당할 수는 없다.
- 또, 최소한의 프레임은 할당해야 한다. 최소한의 프레임을 할당해야 하는 이유는 성능과 관계된다.
    - 각 프로세스에 할당되는 프레임 수가 줄어들면 페이지 폴트율은 증가하고, 프로세스 실행은 늦어지게 된다.
    - 명령어 수행 중에 페이지 폴트가 발생하면, 그 명령어는 재실행 되어야 한다. 따라서 하나의 명령어가 참조하는 모든 페이지는 동시에 메모리에 올라와 있어야 그 명령어 수행을 끝낼 수 있다.
- 프로세스당 최소 프레임 수는 아키텍처에 의해 정의되고, 최대 수는 사용 가능한 물리 메모리 양에 의해 정의된다.

### 5.2 할당 알고리즘_Allocation Algorithm

- n 개의 프로세스에 m 개의 프레임을 할당하는 가장 쉬운 방법은 모두에게 같은 몫 m/n 개의 프레임씩 할당하는 방법이다. (나머지는 가용 프레임 버퍼 저장소로 사용한다.) 이 방법을 **균등 할당**이라 한다.
- 프레세스마다 크기가 다를 때, 가용 메모리를 각 프로세스의 크기 비율에 맞추어 할당하는 방법인 비례 할당을 사용할 수 있다.
    - 프레세스 p(i)의 크기를 s(i)라 하고 모든 프로세스 크기의 합을 S, 가용 프레임 수를 m이라 한다.
    - 할당되는 프레임의 수 `a(i) = s(i) / S * m` 이다.
    - a(i)는 최소 할당수 보다는 큰 정수로, 총합은 m을 넘지 않아야 한다.
- 균등, 비례 할당 모두 다중 프로그래밍 정도에 따라 할당되는 양이 달라진다. 다중 프로그래밍 정도가 높아지면 덜 할당받고, 낮아지면 넉넉히 할당받을 것이다.

### 5.3 전역 대 지역 할당_Global Versus Local Allocation

- 다수의 프로세스가 프레임 할당을 위해 경쟁하는 환경에서 페이지 교체 알고리즘은 크게 두 가지 범주, **전역 교체(global replacement)**와 **지역 교체(local replacement)**로 나눌 수 있다.
- **전역 교체**는 프로세스가 교체할 프레임을 다른 프로세스에 속한 프레임을 포함한 모든 프레임을 대상으로 찾는 경우다.
    - 전역 교체에서는 프로세스가 매번 다른 프로세스의 프레임을 할당받게 되면 그 프로세스에 할당된 프레임 수가 증가하게 된다.
    - 문제점은 프로세스의 페이지 집합이 다른 프로세스의 페이징 동작에도 영향을 받는다.

- **지역 교체**는 각 프로세스가 자기에게 할당된 프레임 중에서만 교체될 희생자를 선택하는 경우다.
    - 지역 교체에서는 프로세스에 할당된 프레임의 수가 바뀌지 않는다. (자기 자신 내에서만 교체)
    - 문제점은 잘 안쓰는 페이지가 프로세스 내에서 낭비될 수 있다. 따라서 일반적으로 전역 교체가 지역 교체보다 더 좋은 시스템 성능을 나타낸다.

### 5.4 비균등 메모리 접근_Non-Uniform Memory Access

- 여러개의 CPU를 가진 시스템에서 특정 CPU는 메인 메모리의 일정 영역을 다른 CPU보다 더 빠르게 접근할 수 있다. 이것을 **비균등 메모리 접근**시스템 이라 한다.
- 이러한 시스템에서 메모리를 동등하게 대하면, 비균등 메모리 접근을 고려한 메모리 할당 알고리즘을 사용하는 시스템에서보다 CPU가 메모리에 접근할 때 대기 시간이 매우 길어지게 된다.

---

## 6. 스래싱_Thrashing

프로세스에 최소 프레임도 없는 경우, 그 프로세스는 곧바로 페이지 폴트를 일으킨다.

이때, 페이지 교체가 필요하지만 이미 활발하게 사용되는 페이지들로만 이루어져 있으므로 어떤 페이지가 교체되든 곧바로 다시 필요하게 될 것이다.

이러한 과도한 페이징 작업을 **스래싱(thrashing)**이라고 부른다. 어떤 프로세스가 실제 실행보다 더 많은 시간을 페이징에 사용하고 있으면 스래싱이 발생했다고 한다.

### 6.1 스래싱의 원인_Cause of Thrashing

- 운영체제는 CPU의 이용률을 감시한다. 만약 이용률이 너무 낮아지면 새로운 프로세스를 시스템에 추가해 다중 프로그래밍 정도를 높인다.
- 이때 어떤 프로세스가 더 새로운 실행 단계로 진입해 더 많은 프레임이 필요하다고 가정하자.
- 페이지 폴트가 발생하며, 다른 프로세스로부터 프레임을 가져올 것이다. 그런데, 교체된 페이지들이 해당 프로세스에서 필요로 하는 것이었다면 계속해서 페이지 폴트를 발생시킬 것이다.
- 페이지들이 페이징 장치를 기다리는 동안 CPU 이용률은 떨어지게 된다. 이용률의 저하를 감지한 운영체제는 또 다중 프로그래밍의 정도를 높인다. 이는 더 많은 페이지 폴트와 긴 페이징 장치 대기 시간을 야기하며, CPU 이용률은 더욱 떨어지고 CPU 스케줄러는 다중 프로그래밍 정도를 더 높일 것이다.
- 결국 스래싱이 일어나게 되어 시스템의 처리율은 대단히 낮아지고 페이지 폴트는 상당히 늘어난다.

![Untitled 9](https://user-images.githubusercontent.com/75190035/177458503-47b636c8-45b0-4301-b92a-c483e87018b6.png)

- 다중 프로그래밍 정도에 따라 CPU 이용률은 높아진다. 하지만 최대값 이상으로 커지면 스래싱이 발생하고 이용률은 급격히 떨어진다.
- 따라서 CPU 이용률을 높이고 스래싱을 중지시키기 위해 다중 프로그래밍 정도를 낮춰야한다.
- 지역 교체 알고리즘으로 스래싱의 영향을 제한할 수 있지만, 완전한 문제 해결은 아니다.
- **스래싱 현상을 방지하기 위해서는 각 프로세스가 필요로 하는 최소한의 프레임 개수를 보장해야 한다.**
- 최소한의 프레임 수를 알아내기 위해 사용하는 한 가지 전략은 프로세스 실행의 **지역성 모델**을 기반으로 한다.
- 지역성 모델이란 프로세스가 실행될 때에는 항상 어떤 특정한 지역에서만 메모리를 집중적으로 참조함을 말한다.

### 6.2 작업 집합 모델_Working-Set Model

- 작업 집합 모델은 지역성을 토대로 하고 있다.
- 기본 아이디어는 🔺만큼의 페이지 참조를 관찰하겠다는 것이다.
- 한 프로세스가 최근 🔺번 페이지를 참조했다면, 그 안에 들어있는 서로 다른 페이지들의 집합을 작업 집합이라고 부른다.
- 작업 집합의 정확도는 🔺의 선택에 따라 좌우된다. 만약 너무 작다면 전체 지역을 포함하지 못할 것이고, 너무 크다면 여러 지역성을 과도하게 수용할 것이다.

아래 작업 집합 모델을 예로들어보자. (🔺= 10 이라고 가정)

![Untitled 10](https://user-images.githubusercontent.com/75190035/177458511-99f42f47-1c41-47f5-8763-ef0c7b793158.png)

t1 시간에서의 작업 집합은 {1, 2, 5, 6, 7}이고, t2 시간에서의 작업 집합은 {3, 4}가 된다.

### 6.3 페이지 폴트 빈도_Page-Fault Frequency

![Untitled 11](https://user-images.githubusercontent.com/75190035/177458516-98ca8937-3259-48fe-b0a2-7ea0d137e45e.png)

- 작업 집합 모델은 아주 성공적이며, 작업 집합에 대해 안다는 것은 선페이징(prepaging) 시에 유용하지만 스래싱을 조절하는 방법으로는 어색하다.
- **페이지 폴트 빈도(PFF)** 방식은 보다 더 직접적으로 스래싱을 조절한다.
- 이 방법에서는 페이지 폴트율의 상한과 하한을 정해놓고, 만약 페이지 폴트율이 상한을 넘으면 그 프로세스에 프레임을 더 할당해주고, 하한보다 낮아지면 그 프로세스의 프레임을 줄인다.
- 페이지 폴트율이 높아졌는데 가용 프레임이 없다면, 한 프로세스를 선택해 그 프로세스를 예비 저장장치로 스왑 아웃시켜야 한다. 이후 이 프로세스에 할당되어있던 프레임들은 높은 페이지 폴트율을 갖는 프로세스들에게 분배된다.
- 이렇게 직접적으로 부재율을 관찰하고 조절함으로써 스래싱을 방지할 수 있다.

---

## 7. 메모리 압축_Memory Compression

페이징의 대안으로 **메모리 압축**을 사용할 수 있다.

메모리 압축에서는 수정된 프레임을 스왑 공간으로 페이징 아웃하지 않고 여러 프레임을 하나의 프레임으로 압축한다. 이러면 시스템이 페이지 스와핑에 의존하지 않고 메모리 사용량을 줄일 수 있게 된다.

다음과 같은 시스템이 있다고 가정하자.

![Untitled 12](https://user-images.githubusercontent.com/75190035/177668593-6036401f-eeb8-49fd-a89e-b6e571663f7c.png)

메모리 압축 전략을 사용하면 여러 프레임을 압축하고 압축된 버전을 하나의 페이지 프레임에 저장한다.

![Untitled 13](https://user-images.githubusercontent.com/75190035/177668597-32846ec4-0262-48a1-b1c1-212fdb3c585f.png)

가용 프레임 리스트에 있는 프레임 7은 가용 프레임 리스트에서 제거되고, 프레임 (15, 3, 35)는 압축되어 프레임 7에 저장된다.

이후 프레임(15, 3, 35)는 가용 프레임 리스트로 이동된다. 또한 나중에 이들 중 하나가 참조되면 페이지 폴트가 발생하고, 압축된 프레임이 압축 해제되어 세 개의 페이지가 메모리에 복원된다.

---

> 참고
> 
> - 책
> 
> [⌜Operating System Concepts 10th - Abraham Silberschatz, Peter B. Galvin, Greg Gagne⌟](http://www.yes24.com/Product/Goods/78225791)
> 
> - 블로그
> 
> [https://will-behappy.tistory.com/25?category=808600](https://will-behappy.tistory.com/25?category=808600)
>
