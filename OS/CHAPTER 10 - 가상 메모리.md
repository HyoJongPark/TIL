# CHAPTER 10 - 가상 메모리

9장의 메모리 관리 전략들은 모두 다중 프로그래밍을 실현하기 위해 메모리에 많은 프로세스를 동시에 유지하는 것을 목적으로 했다. 

그러나 이 전략에서 접근 방식은 프로세스 전체가 실행되기 전에 메모리로 올라와야 한다는 것을 전제로 한다.

**가상 메모리(virtual memory)**라는 것은 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법이다. 이 기법의 장점은 사용자 프로그램이 물리 메모리보다 커져도 된다는 점이다.

즉, 이 기법을 통해 프로그래머는 메모리의 크기에 제약으로부터 자유로워진다. 또한 가상 메모리는 파일과 라이브러리의 공유를 쉽게 해주고 공유 메모리 구현을 가능하게 해준다.

단점은 구현하기 어렵고, 잘못 사용하게 되면 성능이 현저히 저하될 수 있다.

## 1. 배경_Background

- 실행 중인 코드는 반드시 물리 메모리에 있어야 한다는 조건은 필요하고 타당한 요구조건으로 보이지만, 프로그램의 크기를 물리 메모리의 크기로 제한한다는 점 때문에 환영할만한 조건이 아니다.
- 다음 예시들을 생각해보면 프로그램 전체가 꼭 메모리에 올라와 있어야 하는 것은 아니라는 것을 알 수 있다.
    - 프로그램에는 잘 발생하지 않는 예외처리 코드가 종종 존재한다. 이런 오류들은 실질적으로 거의 발생하지 않으므로, 이 코드들은 잘 실행되지 않는다.
    - 배열, 리스트, 테이블 등은 필요 이상으로 많은 공간을 점유할 수 있다.
    - 프로그램 내의 어떤 옵션이나 기능들은 거의 사용되지 않는다.
- 만약 프로그램의 일부분만 올려놓고 실행할 수 있다면, 다음과 같은 이점을 얻을 수 있다.
    - **프로그램은 물리 메모리 크기에 제약을 받지 않게 된다.** 사용자들은 매우 큰 가상 주소 공간을 가정하고 프로그램을 만들 수 있으므로, 프로그래밍 작업이 간단해진다.
    - 각 프로그램이 더 작은 메모리를 차지해 **더 많은 프로그램이 동시에 실행될 수 있다.** 이에 따라 응답시간은 늘어나지 않으면서 CPU 이용률과 처리율이 높아진다.
    - 프로그램을 메모리에 올리고 스왑하는데 필요한 I/O 회수가 줄어들기 떄문에 **프로그램들이 보다 빨리 실행된다.**
- **가상 메모리**는 실제의 물리 메모리 개념과 개발자의 논리 메모리 개념을 분리한 것으로, 작은 메모리를 가지고도 얼마든지 큰 가상 주소 공간을 프로그래머에게 제공할 수 있다.

---

## 2. 요구 페이징_Demand Paging

프로그램을 보조저장장치에서 메모리로 적재하는 한 가지 방법은 프로그램 실행 시 프로그램의 전부를 메모리에 저장하는 것이다.

이 방법의 문제는 초기에는 프로그램의 전체가 메모리에 있을 필요는 없을지도 모른다는 점이다.

다른 전략은 필요한 페이지만 적재하는 것이다. 이것은 **요구 페이징(demand paging)**이라 하며, 가상 메모리 시스템에서 일반적으로 사용된다.

요구 페이징 가상 메모리를 사용하면, 프로그램 실행 중 필요할 때만 페이지가 적재된다.

### 2.1 기본 개념_Basic Concepts

![Untitled](https://user-images.githubusercontent.com/75190035/177242074-48a69ef1-71fc-487b-a285-c3007f37db5a.png)

- 요구 페이징을 구현하기 위해 **유효-무효비트 기법**이 사용된다.
    - **비트가 유효**하다고 설정되면, 해당 페이지가 메모리에 있다는 것을 의미한다.
    - **비트가 무효**하다고 설정되면 해당 페이지가 유효하지 않거나, 유효하지만 보조저장장치에 존재한다는 것을 의미한다.
- 프로세스가 메모리에 올라와 있지 않은 페이지에 접근하려고 하면, 테이블 항목이 **무효**로 설정되어 있으므로 **페이지 폴트 트랩**을 발생시킨다.
- **순수 요구 페이징(pure demand paging)**
    - 극단적인 경우에 메모리에 페이지가 하나도 올라와있지 않은 상황에서 프로세스를 실행시킬 수 있다.
    - 운영체제에서 명령 포인터의 값을 프로세스의 첫 명령으로 설정하는 순간, 메모리에 존재하지 않는 페이지에 있으므로 페이지 폴트를 발생시킨다.
    - 페이지가 적재되고 난 후 실행을 계속하는데 프로세스가 사용하는 모든 페이지가 메모리에 올라올 때까지 필요할 때마다 페이지 폴트가 발생한다.
    - 이것이 **순수 요구 페이징**이고, **어떤 페이지가 필요해지기 전에는 결코 그 페이지를 적재하지 않는 방법이다.**
- 프로그램들은 한 명령어에서도 여러 개의 페이지 폴트가 발생할 수 있다. 이렇게 되면 시스템 성능의 저하를 초래한다.
- 다만, 모든 프로그램은 **참조의 지역성(locality of reference)**이라는 성질이 있어 어느 한 특정 작은 부분만 집중적으로 참조하는데, 이러한 성질 때문에 요구 페이징은 만족할 만한 성능을 보인다.
- 요구 페이징을 지원하기 위한 하드웨어
    - 페이지 테이블: 유효/무효 비트를 통해 특정 항목을 무효로 설정할 수 있어야 한다.
    - 보조저장장치: 메인 메모리에 없는 모든 페이지를 가지고 있다. 보통은 고성능의 디스크 또는 NVM 장치다.

---

### 2.2 요구 페이징의 성능_Performance of Demand Paging

- 요구 페이징은 컴퓨터 시스템의 성능에 큰 영향을 줄 수 있다.
- **실질 접근 시간**
    - 페이지 폴트가 없는 한 실질 접근 시간은 메모리 접근 시간과 같다. 그러나 페이지 폴트가 발생하면, 먼저 보조저장장치에서 해당 페이지를 읽은 다음 원하는 워드에 접근해야 한다.
    - 실질 접근시간 = (1-p) * ma + p * 페이지 폴트 시간
        - p = 페이지 폴트 확률, ma = 메모리 접근 시간
- **실질 접근 시간은 페이지 폴트율에 비례**하며, 페이지 폴트 처리 시간은 크게 3 가지로 이루어 진다.
    1. 인터럽트의 처리
    2. 페이지 읽기
    3. 프로세스 재시작
- 요구 페이징의 또 다른 특성 중 하나는 스왑 공간의 관리이다.
- 시스템이 더 나은 처리량을 얻는 옵션 중 첫번째는 프로세스 시작 시 전체 파일 이미지를 스왑 공간에 복사한 다음 스왑 공간에서 요구 페이징을 수행하는 것이다. 이 방법은 프로그램 시작 시 파일 이미지를 복사하는 단점이 있다.
- 시스템이 더 나은 처리량을 얻는 옵션 중 두 번째 방법은 프로그램을 처음 시작시킬 때에는 파일 시스템으로부터 요구 페이징을 처리하지만, 그 페이지들이 교체될 떄는 스왑 공간에 페이지를 기록하는 것이다.
- 두 번째 방법은 파일 시스템으로부터는 꼭 필요한 페이지들만 읽어 오면서, 그 페이지를 다시 읽어올 때는 스왑 공간에서 읽어온다는 것을 보장한다.

> 실질 접근 시간을 계산하기 위해 페이지 폴트를 처리하는 데 얼마나 많은 시간이 걸리는지 알아야 한다. 페이지 폴트는 다음 순서로 처리된다.
> 
> 1. 운영체제에 트랩을 요청한다.
> 2. 레지스터들과 프로세스 상태를 저장한다.
> 3. 인터럽트 원인이 페이지 폴트임을 알아낸다.
> 4. 페이지 참조가 유효한 것인지 확인하고, 보조저장장치에 있는 페이지의 위치를 알아낸다.
> 5. 저장장치에 가용 프레임으로의 읽기 요구를 낸다.
>     1. 읽기 차례가 돌아오기까지 대기 큐에서 기다린다.
>     2. 디스크에서 찾는 시간과 회전 지연 시간동안 기다린다.
>     3. 가용 프레임으로 페이지 전송을 시작한다.
> 6. 기다리는 동안 CPU 코어는 다른 사용자에게 할당된다.
> 7. 저장장치가 다 읽었다고 인터럽트를 건다.(I/O 완료)
> 8. 다른 프로세스의 레지스터들과 프로세스 상태를 저장한다.(6단계가 실행되었을 경우)
> 9. 인터럽트가 보조저장장치로부터 왔다는 것을 알아낸다.
> 10. 새 페이지가 메모리로 올라왔다는 것을 페이지 테이블과 다른 테이블들에 기록한다.
> 11. CPU 코어가 자기 차례로 오기까지 기다린다.
> 12. CPU 차례가 오면 위에서 저장시켜두었던 레지스터, 프로세스 상태, 새로운 페이지 테이블을 복원시키고 인터럽트되었던 명령어를 다시 실행한다.

---

## 3. 쓰기 시 복사_Copy-on-Write

![Untitled 1](https://user-images.githubusercontent.com/75190035/177242097-404f0b81-fe74-4e0c-99d9-ddd811279acd.png)

`fork()` 시스템 콜을 통해 프로세스를 생성할 때는 페이지 공유와 비슷한 기법으로 첫 요구 페이징조차 생략하는 것이 가능하다.

- `fork()` 를 하면 부모 프로세스의 페이지들을 실제로 자식 프로세스에 복사해 줌으로써 자식 프로세스의 주소 공간을 구성해 준다.
- 하지만 대부분의 자식은 이후 `exec()` 시스템 콜을 한다. 그러면 부모로부터 복사해온 페이지들은 다 쓸모없는 것들이 된다.
- 부모의 페이지들을 다 복사해오는 대신 **쓰기 시 복사(copy-on-write) 방식**을 사용할 수 있다.
- 이 방식에서는 자식 프로세스가 시작할 때 부모의 페이지를 당분간 함께 사용하도록 한다. 이때 공유되는 페이지를 쓰기 시 복사 페이지라고 표시한다.
- 둘 중 한 프로세스가 공유 중인 페이지에 쓸 때 그 페이지의 복사본이 만들어진다.
- 수정되지 않는 페이지들은 부모, 자식 간에 계속 공유될 수 있다.
- 쓰기 시 복사 시에는 자식이 부모 주소 공간의 페이지에 변경을 가하지 않도록 주의해야 한다.

---

## 4. 페이지 교체_Page Replacement

### 4.1 기본적인 페이지 교체_Basic Page Replacement

<img width="430" alt="Untitled 2" src="https://user-images.githubusercontent.com/75190035/177242100-764a6bcb-9eb6-4d80-8d8d-66477138d55a.png">

- 페이지 교체를 포함한 페이지 폴트 서비스 루틴은 다음과 같다.
    1. 보조저장장치에서 필요한 페이지의 위치를 알아낸다.
    2. 빈 페이지 프레임을 찾는다.
        1. 비어 있는 프레임이 있다면 그것을 사용한다.
        2. 비어 있는 프레임이 없다면 **희생될(victim) 프레임을 선정**하기 위해 페이지 교체 알고리즘을 가동시킨다.
        3. 희생될 페이지를 보조저장장치에 기록(필요한 경우), 관련 테이블을 수정해야 한다.
    3. 빼앗은 프레임에 새 페이지를 읽어오고 테이블을 수정한다.
    4. 페이지 폴트가 발생한 지점에서부터 프로세스를 계속한다.
- 빈 프레임이 없는 경우에는 디스크에 두 번 접근해야하므로 페이지 폴트 처리 시간이 2배 소요며, 그에 따라 실질 접근 시간도 증가한다.
    - 한 번은 프레임을 비울 때, 다른 한 번은 읽어 들일 때
- 이러한 오버헤드는 변경 비트를 사용해서 감소시킬 수 있다.
    - 변경 비트는 CPU가 페이지 내의 어떤 바이트라도 쓰게 되면 페이지가 변경되었음을 나타내기 위해 설정된다.
    - 희생시킬 페이지가 선정되면 변경 비트를 확인한다. 이때 변경 비트가 설정되어 있으면 페이지 내용이 변경되었음을 알 수 있다.
- 요구 페이징 시스템은 두 가지 중요한 문제를 해결해야 하는데, **프레임 할당 알고리즘**과 **페이지 교체 알고리즘**이다.
- 즉, 여러 프로세서가 존재하는 경우 각 프로세스에 얼마나 많은 프레임을 할당해야 하는지 결정해야 한다.

> **참조열(reference string)**
> 
> 
> 페이지 교체 알고리즘의 성능은 특정 메모리 참조 나열에 대해 알고리즘을 적용해 페이지 폴트 발생 횟수를 계산해 평가한다. 이러한 메모리 주소 나열을 **참조열**이라 한다.
> 
> 다음과 같은 주소 열에서
> 
> ```python
> 0100, 0432, 0101, 0612, 0102, 0103, 0104, 0101, 0611, 0102, 0103,
> 0104, 0101, 0610, 0102, 0103, 0104, 0101, 0609, 0102, 0105
> ```
> 
> 페이지 크기가 100 바이트라면, 이 열은 다음과 같은 참조열로 줄일 수 있다.
> 
> ```python
> 1, 4, 1, 6, 1, 6, 1, 6, 1
> ```
> 
> 페이지 크기가 주어졌을 때, 주소 전체를 고려하기보다 페이지 번호만 고려하면 된다.
> 
> 페이지 p에 대한 참조가 발생하면, 직후에 p에 접근하는 모든 참조는 페이지 폴트를 발생시키지 않는다. 따라서 다음과 같은 결과를 얻은 것이다.
> 
> 가용 프레임 수와 페이지 폴트의 상관관계는 다음과 같다.
> 
> <img width="460" alt="Untitled 3" src="https://user-images.githubusercontent.com/75190035/177242123-8f09ec08-6a3d-4b8a-9cb3-c788a1ed293b.png">
> 

---

### 4.2 FIFO 페이지 교체_FIFO Page Replacement

- 가장 간단한 페이지 교체 알고리즘이다.
- FIFO 알고리즘은 어떤 페이지를 교체해야 할 때, 그 희생량(victim)으로 올라온지 가장 오래된 페이지를 선택한다.
- 페이지가 올라온 시간을 페이지마다 기록해도 되고, 페이지들이 올라온 순서대로 큐(FIFO queue)를 가지고 있어도 된다.

**예시 1.**

다음과 같은 참조열이 있고, 3개의 프레임을 갖는 시스템이 있다고 가정하자

```python
7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1
```

처음 3개의 참조(7, 0, 1)는 페이지 폴트를 발생시키고 빈 프레임에 적재된다. 이후 7 → 0 → 1 순서로 희생량으로 선택될 것이다. 결국 총 15개의 페이지 폴트가 발생하며, 전체 결과는 다음과 같다.

<img width="496" alt="Untitled 4" src="https://user-images.githubusercontent.com/75190035/177242136-1c93eaba-b46b-4ba9-abf7-2c442d8638a4.png">

- FIFO 페이지 교체 알고리즘은 이해하기도 쉽고, 프로그램하기도 쉽다. 그러나 성능이 항상 좋지는 않다.
- 교체된 페이지가 활발하게 사용되고 있는 페이지일 경우 정상적으로 동작 하겠지만, 교체된 이후 거의 즉시 그 페이지를 다시 적재하기 위해 페이지 폴트가 발생할 것이다.
- **잘못된 교체 결정을 페이지 폴트율을 높이고 프로세스 실행 속도를 떨어뜨린다.**

**예시 2.**

한 시스템이 다음과 같은 참조열을 갖는다고 가정하자.

```python
1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5
```

프레임 개수 별 페이지 폴트 횟수는 다음과 같다.

<img width="394" alt="Untitled 5" src="https://user-images.githubusercontent.com/75190035/177242144-5517201c-d4a1-4bfd-8947-3eb87558a759.png">

- 결과에서 프레임이 4개인 경우가 3개인 경우보다 페이지 폴트 횟수가 더 많다.
- 이전에 프레임 개수가 페이지 폴트 횟수와 반비례한다는 점과 상반된 결과다. 즉, 상식 밖의 결과다.
- 이런 현상을 **Belady의 모순(Belady’s anomaly)**이라고 부른다.
- Belay의 모순은 프로세스에 더 많은 프레임을 주었는데 오히려 페이지 폴트율은 더 증가하는 현상을 일컫는다.

---

### 4.3 최적 페이지 교체_Optimal Page Replacement

- 최적 교체 정책이란 모든 알고리즘보다 낮은 페이지 폴트율을 보이며, Belady의 모순이 발생하지 않는 것이다.
- 최적 교체 알고리즘에서는 앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체한다.
- 이 알고리즘은 할당된 프레임 수가 고정된 경우 가장 낮은 페이지 폴트율을 보장한다.

**예시.**

다음과 같은 참조열이 있고, 3개의 프레임을 갖는 시스템이 있다고 가정하자

```python
7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1
```

처음 3개가 적재된 후, 가장 오랫동안 사용되지 않을 순서로 희생량이된다. (7 → 1 → …)

이 알고리즘에서 페이지 폴트는 9번 발생했으며, 결과는 다음과 같다.

<img width="498" alt="Untitled 6" src="https://user-images.githubusercontent.com/75190035/177242158-d9b1e0ed-153d-4e25-997a-c0081b7bb53c.png">

- 이 방식은 프로세스가 앞으로 메모리를 어떻게 참조해야하는지 미리 알아야하기 때문에 실제 구현은 어렵다.

---

### 4.4 LRU 페이지 교체_LRU Page Replacement

- 최적 알고리즘이 거의 불가능하기 때문에, 대신 최적 알고리즘의 근사 알고리즘을 사용한다.
- LRU 알고리즘에서는 **사용될** 시간이 아닌 가장 오랜 시간동안 **사용되지 않은** 페이지를 교체한다.
    - 미래 시간 대신 과거 시간에 대해 적용한 최적 교체 정책
- 따라서, LRU 알고리즘에서는 페이지마다 마지막 사용 시간을 유지한다.
- 구현 방법
    - **계수기(counters)**
        - 가장 간단한 구현 방법으로, **각 페이지 항목마다 사용 시간 필드를 넣는 것**이고, CPU에 논리적인 시계나 계수기를 추가한다.
        - 시간 값이 가장 작은 페이지가 교체된다.
        - 이 기법에서는 LRU 페이지를 찾기 위해 페이지 테이블을 탐색해야 하며, 메모리 참조 때마다 메모리 쓰기 작업을 필요로 한다.
    - 스택(stack)
        - **페이지 번호의 스택을 유지하는 방법이다.**
        - 페이지가 참조될 때마다 페이지 번호는 스택 중간에서 제거되어 스택 꼭대기에 놓이게 된다.
        - 결론적으로 바닥(bottom)에는 가장 오랫동안 사용되지 않은 페이지 번호가, 꼭대기(top)에는 가장 최근에 사용된 페이지 번호가 위치하게 된다.
        - 스택 중간에서 항목을 제거해야 할 필요가 있으므로 보통 doubly linked list로 구현된다.
- 계수기 값과 스택을 갱신하는 일이 메모리 참조 때마다 수행되어야 한다.
- 이러한 작업을 소프트웨어로 하기 위해 인터럽트를 사용하면 메모리 참조 속도가 느려지고, 결국 모든 프로세스의 실행 속도를 그만큼 저하시키게 된다.

**예시.**

다음과 같은 참조열이 있고, 3개의 프레임을 갖는 시스템이 있다고 가정하자.

```python
7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1
```

처음 3개가 적재된 후, 가장 오랫동안 사용되지 않은 순서로 희생량이된다. (7 → 1 → 2 → …)

이 알고리즘에서 페이지 폴트는 12번 발생했으며, 결과는 다음과 같다.

<img width="493" alt="Untitled 7" src="https://user-images.githubusercontent.com/75190035/177242165-89c252f7-5bfa-41bb-8522-b3da0c6e68a0.png">

---

### 4.5 LRU 근사 페이지 교체_LRU Approximation Page Replacement

- LRU 페이지 교체 지원을 충분히 할 수 있는 하드웨어는 많지 않다.
- 많은 시스템은 참조 비트(reference bit)의 형태로 어느 정도의 지원은 하고 있다.
- 페이지 참조가 있을 때마다 하드웨어가 그 페이지에 대한 참조 비트를 설정한다. 참조 비트는 페이지 테이블에 있는 각 항목과 대응된다.
- 처음에 모든 참조 비트는 운영체제에 의해 0으로 채워지고, 이후 참조되는 페이지의 비트는 하드웨어가 1로 세팅한다.
- 사용 순서는 모르지만, 어떤 페이지가 그동안 사용되었고, 한 번도 사용되지 않았는지는 알 수 있고, 이 정보가 많은 LRU 근사 알고리즘의 기본이 된다.

**4.5.1 부가적 참조 비트 알고리즘_Additional-Refrence Bits Alogrithm**

- 일정한 간격마다 참조 비트들을 기록함으로써 추가적인 선후 관계 정보를 얻을 수 있다.
- 각 페이지에 대해 8비트의 참조 비트를 할당하고, 일정 시간마다 타이머 인터럽트를 걸어 참조 비트를 정보의 최상위 비트로 이동시키고, 나머지 비트들은 하나씩 오른쪽으로 이동시킨다.
- 예) 00000000은 한 번도 사용되지 않은 페이지, 10000000은 01111111 보다 더 최근에 사용된 페이지다.

**4.5.2 2차 기회 알고리즘_Second-Chance Algorithm**

<img width="431" alt="Untitled 8" src="https://user-images.githubusercontent.com/75190035/177242177-004e94ae-daf4-4726-8670-27b828d658c3.png">

- 2차 기회 알고리즘의 기본은 FIFO 교체 알고리즘이다. 그러나 페이지가 선택될 때마다 참조 비트를 확인한다.
- 참조 비트가 0이면 페이지를 교체하고 1이면 다시 한번 기회를 주고 다음 FIFO페이지로 넘어간다.
- 따라서, 참조 비트가 계속 설정되어 있을 정도로 자주 사용되는 페이지는 전혀 교체되지 않을 것이다.

**4.5.3 개선된 2차 기회 알고리즘_Enhanced Second-Chance Algorithm**

- 2차 기회 알고리즘에서 변경 비트를 조합한 알고리즘이다. 두 개의 비트를 조합해 다음 4가지 등급을 나타낼 수 있다.
1. (0, 0) : 최근에 사용되지도, 변경되지도 않은 경우 - 교체하기 가장 좋은 페이지
2. (0, 1) : 최근에 사용되지는 않았지만, 변경은 된 경우 - 이 페이지를 희생량으로 선택하면, 디스크에 수정 내용을 기록해야 하므로 희생량으로 적절하지 않다.
3. (1, 0) : 최근에 사용은 되었으나 변경은 되지 않은 경우 - 이 페이지는 곧 다시 사용될 가능성이 높다.
4. (1, 1) : 최근에 사용 되었고, 변경도 된 경우 - 아마 곧 다시 사용될 것이며, 희생량으로 적절하지도 않다.
- 페이지 교체가 필요할 때는 참조 비트를 확인하는 것이 아닌, 어떤 등급에 속하는지 확인한다. 그중 가장 낮은 등급을 가지면서 처음 만난 페이지를 교체한다.
- 교체될 페이지를 찾기까지 순환 큐를 여러번 검사할 수 있다.

---

### 4.6 계수-기반 페이지 교체_Counting-Based Page Replacement

- **LFU 알고리즘(Least Frequently Used Algorithm)**
    - 참조 횟수가 가장 적은 페이지를 교체하는 방법이다.
    - 이 알고리즘은 어떤 프로세스가 초기에만 한 페이지를 집중적으로 사용하다 이후 사용하지 않게되면 판단이 빗나갈 수 있다.
    - 집중적으로 사용됨으로 인해 참조 횟수가 커지고 이후 사용하지 않더라도 계속 메모리에 머물 것이다.
- **MFU 알고리즘(Most Frequently Used)**
    - 가장 작은 참조 회수를 가진 페이지가 가장 최근에 참조된 것이라고 판단하고, 참조 회수가 가장 큰 페이지를 교체한다.
    
---

### 4.7 페이지-버퍼링 알고리즘_Page-Buffering Algorithm

- 페이지 교체 알고리즘과 병행하여 여러 가지 버퍼링 기법이 사용될 수 있다.
    1. 시스템들이 가용 프레임 여러 개를 풀로 가지고 있다가, 페이지 폴트가 발생하면 예전과 마찬가지로 교체될 페이지를 찾지만, 교체될 페이지의 내용을 디스크에 기록하기 전 가용 프레임에 새로운 페이지를 먼저 읽어 들이는 방법.
        1. 교체될 페이지가 쓰이기를 기다리지 않고 프로세스가 가능한 빨리 시작할 수 있도록 해준다.
        2. 교체될 페이지가 다 쓰이면, 그 프레임이 가용 프레임 풀에 추가된다.
    2. 가용 프레임 풀을 유지하지만 그 속에 각 프레임의 원래 임자 페이지가 누구였는지 기억하는 방법.
        1. 풀 속의 프레임 내용은 그것을 보조장치에 썼다고 하더라도 수정되지 않았을 확률이 있으므로 거기에 저장되어 있던 페이지는 프레임이 사용되기 전까지는 다시 사용될 수 있기 때문이다.

---

## 5. 프레임의 할당_Allocation of Frames

---

> 참고
> 
> - 책
> 
> [⌜Operating System Concepts 10th - Abraham Silberschatz, Peter B. Galvin, Greg Gagne⌟](http://www.yes24.com/Product/Goods/78225791)
> 
> - 블로그
> 
> [https://will-behappy.tistory.com/25?category=808600](https://will-behappy.tistory.com/25?category=808600)
>
