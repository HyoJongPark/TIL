# CHAPTER 9 - 메인 메모리

## 1.  배경_Background

메인 메모리는 현대 컴퓨터 시스템의 운영에 중심적인 역할을 한다. 

메모리는 각각 주소가 할당된 일련의 바이트들로 구성된다.

### 1.1 기본 하드웨어_Basic Hardware

<img width="299" alt="Untitled" src="https://user-images.githubusercontent.com/75190035/176337381-a8c5fa01-82bf-4fa4-a7e1-bae4ef195245.png">

- 메인 메모리와 각 처리 코어에 내장된 레지스터들은 CPU가 직접 접근할 수 있는 유일한 범용 저장장치다.
    - 따라서 모든 실행되는 명령어와 데이터들은 CPU가 직접적으로 접근할 수 있는 메인 메모리와 레지스터에 있어야 한다.
    - 데이터가 메모리에 없다면, CPU가 그것들을 처리하기 전에 메모리로 이동시켜야 한다.
- 각 CPU 코어에 내장된 레지스터들은 일반적으로 CPU 클록(clock)의 1 사이클(cycle)내에 접근 가능하다.
- 메모리 버스를 통해 전송되는 메인 메모리는 메인 메모리에 대한 접근을 완료하기 위해서 많은 CPU 클록 틱 사이클이 소요된다.
    - 이 경우 CPU가 필요한 데이터가 없어서 명령어를 수행하지 못하고 지연되는(shell) 현상이 발생하게 된다.
    - CPU와 메인 메모리 사이에 빠른 속도의 메모리(캐시)를 추가해 해결 할 수 있다.
- 시스템이 올바르게 동작하기 위해서는 사용자 프로그램으로부터 운영체제 영역을 보호해야 할 뿐만 아니라 사용자 프로그램 사이도 서로 보호해야한다.
    - 운영체제가 CPU-메모리 간의 접근 중에 개입하게 되면 성능이 떨어지기 때문에 이러한 보호 기법은 하드웨어가 지원해야 한다.
    - 이 보호 기법을 위해 각각의 프로세스가 독립된 메모리 공간을 가지도록 보장해야 한다.
    - 기준 레지스터와 상한 레지스터라는 두 개의 레지스터를 사용해 보호 기법을 제공할 수 있다.
        - 기준 레지스터: 가장 작은 합법적인 물리 메모리 주소 값을 저장
        - 상한 레지스터: 주어진 영역의 크기를 저장
        - 예) 기준(300040), 상한(120900) 이라면, 프로그램은 300040 ~ 420940 까지의 모든 주소를 접근할 수 있다.

<img width="470" alt="Untitled 1" src="https://user-images.githubusercontent.com/75190035/176337390-ad980ac9-674f-42ac-ba45-f013580d0d5d.png">

### 1.2 주소의 할당_Address Binding

- 프로그램은 이진 실행 파일 형태로 디스크에 저장되어 있다. 실행하려면 프로그램을 메모리로 가져와서 프로세스 문맥 내에 배치해야 한다.
- 이 시점에서 가용한 CPU에서 실행할 수 있게 된다.
- 프로세스가 실행되면 메모리에서 명령 및 데이터에 엑세스한다. 이후 프로세스가 종료되고 다른 프로세스에서 사용하기 위해 메모리가 회수된다.
- 대부분의 시스템은 사용자 프로세스가 메모리 내 어느 부분으로도 올라올 수 있도록 지원하고 있다.
- 사용자 프로그램은 여러 단계를 거쳐 실행되기 떄문에 이들 단계를 거치는 동안 여러 가지 다른 표현 방식을 거치게 된다.

<img width="382" alt="Untitled 2" src="https://user-images.githubusercontent.com/75190035/176337397-6e3cb194-b67e-4778-ba6a-7e0286d9275a.png">

- 전통적으로 메모리 주소 공간에서 명령어와 데이터 바인딩은 그 바인딩이 이루어지는 시점에 따라 다음과 같이 구분된다.
    - **컴파일 시간**(compile time) 바인딩: 프로세스가 메모리 내에 들어갈 위치를 컴파일 시간에 미리 알 수 있으면 컴파일러는 **절대 코드**를 생성할 수 있다.
    - **적재 시간**(load time) 바인딩: 프로세스가 메모리 내 어디로 올라오게 될지를 컴파일 시점에 알지 못하면 컴파일러는 일단 **이진 코드를 재배치 가능 코드**로 만들어야 한다.
    - **실행 시간**(execution time) 바인딩: 프로세스가 실행하는 중간에 메모리 내의 한 세그먼트로 부터 다른 세그먼트로 옮겨질 수 있다면 우리는 바인딩이 실행 시간까지 허용되었다고 이야기한다.

### 1.3 논리 대 물리 주소 공간_Logical-Versus Physical-Address Space

<img width="425" alt="Untitled 3" src="https://user-images.githubusercontent.com/75190035/176337402-609eb0ce-25e2-4144-a76b-c1e31c7f90a1.png">

- CPU가 생성하는 주소를 일반적으로 **논리 주소**(logical address)라 하며, 반면에 메모리가 취급하게 되는 주소는 일반적으로 물리 주소(physical address)라 한다.
- 컴파일 또는 적재 시에 주소를 바인딩하면 논리 주소와 물리 주소가 같다.
- 실행 시간 바인딩 기법에서는 두 주소가 다른데 이때, 논리 주소를 **가상 주소**(virtual address)라 한다.
- 프로그램에 의해 생성된 모든 논리 주소 집합을 **논리 주소 공간**이라 하며, 이 논리 주소와 일치하는 모든 물리 주소 집합을 **물리 주소 공간**이라 한다.
- 프로그램 실행 중에는 이와 같은 가상 주소를 물리 주소로 바꿔줘야 하는데 이 변환 작업은 하드웨어 장치인 **메모리 관리 장치**(memory management unit, **MMU**)에 의해 실행된다.
    - 만약 재배치 레지스터(relocation register)가 14000 이라면, 논리 주소 346 번지에 엑세스할 때, 실제는 메인 메모리의 14346번지에 엑세스 하게 된다.

### 1.4 동적 적재_Dynamic Loading

- 지금까지는 프로세스가 실행되기 위해 그 프로세스 전체가 미리 메모리에 올라와 있어야 했다. 이 경우 프로세스의 크기는 모모리의 크기보다 커서는 안된다.
- 메모리 공간을 더 효율적으로 이용하기 위해서 **동적 적재(dynamic loading)**를 해야 한다**.**
- 동적 적재의 장점은 루틴/데이터가 필요한 경우에만 적재된다는 것이다.
- 이러한 구조는 오류 처리 루틴과 같이 아주 간혹 발생하면서도 실행할 코드가 많은 경우에 특히 유용하다.

### 1.5 동적 연결 및 공유 라이브러리_Dynamic Linking & Shared Libraries

- 공통 라이브러리 루틴을 메모리에 중복으로 올리는 것은 낭비다.
- **동적 연결 라이브러리(DLL)**는 사용자 프로그램이 실행될 때, 사용자 프로그램에 연결되는 시스템 라이브러리다.
- 동적 연결에서는 연결이 실행 시기까지 미루어지고, 라이브러리를 여러 프로세스간에 공유할 수 있어 메인 메모리에 DLL 인스턴스가 하나만 있을 수 있다.

---

## 2. 연속 메모리 할당_Contiguous Memory Allocation

메모리는 일반적으로 두 개의 부분으로 나누어진다. 하나는 운영체제를 위한 메모리, 나머지는 사용자 프로세스를 위한 메모리다.

### 2.1 메모리 보호_Memory Protection

<img width="424" alt="Untitled 4" src="https://user-images.githubusercontent.com/75190035/176578819-65e9378d-04c1-4cad-8500-31910c4ec904.png">

- 시스템이 상한 레지스터와 재배치 레지스터를 가지고 있다면, 프로세스가 자신이 소유하지 않은 메모리를 접근할 수 없게 강제할 수 있다.
- CPU 스케줄러가 다음으로 수행할 프로세스를 선택할 때, 디스패처는 문맥 교환의 일환으로 재배치 레지스터와 상한 레지스터에 정확한 값을 적재한다.
- CPU에 의해서 생성되는 모든 주소는 이 레지스터들의 값을 참조해서 확인 작업을 거치기 때문에, 운영체제와 다른 사용자 프로그램을 현재 수행 중인 사용자 프로그램의 접근으로부터 보호할 수 있다.

### 2.2 메모리 할당_Memory Allocation

<img width="416" alt="Untitled 5" src="https://user-images.githubusercontent.com/75190035/176578823-bebe16fe-6d08-4c03-b86d-9333d30e4b9d.png">

- 메모리를 할당하는 가장 간단한 방법 중 하나는 프로세스 메모리를 가변 크기 파티션에 할당하는 것이다.
- 각 파티션에는 정확히 하나의 프로세스만 적재될 수 있다.
- 이 **가변 파티션 기법**에서 운영체제는 사용 가능한 메모리 부분과 사용 중인 부분을 나타내는 테이블을 유지한다.
- 처음에는 모든 메모리가 사용자 프로세스에서 사용 가능하며, 하나의 큰 사용 가능한 메모리 블록으로 구성되어 있다. 이때, 1 개의 hole이 있다고 한다.
- 일반적으로 메모리에는 다양한 크기의 hole이 여기저기 산재하게 된다.
- 이러한 메모리에서 **동적 메모리 할당 문제**가 있을 수 있다.
    - 가용 공간-리스트로부터 크기 n바이트 블록을 요구하는 것을 어떻게 만족시켜 줄 것인가를 결정하는 문제
- 해결책(연속 메모리 할당 방식)
    - **최초 적합**: **첫 번째 사용 가능한 가용 공간**을 할당한다.
        - 속도 면에서 이점이 있다.
    - **최적 적합**: 사용 가능한 공간들 중 **가장 작은 것(크기가 가장 비슷한 것)**을 할당한다.
        - 이용률 면에서 이점이 있다.
        - 리스트가 크기 순 정렬이 되어있지 않다면, 전체 리스트를 검색해야 한다.
    - **최악 적합**: **가장 큰 가용** 공간을 할당한다.
        - 리스트가 크기 순 정렬이 되어있지 않다면, 전체 리스트를 검색해야 한다.

### 2.3 단편화_Fragmentation

- **외부 단편화(external fragmentation)**: 유휴 공간들을 모두 합치면 충분한 공간이 되지만, 작은 조각들로 분산되어 있어 프로세스를 할당할 수 없는 경우
- 최초, 최적 적합 전략 모두 **외부 단편화**로 인해서 어려움을 겪는다.
- 최초 적합의 경우 통계적인 분석을 하면, N개의 블록이 할당되었을 때 0.5N개의 블록이 단편화 때문에 손실될 수 있다는 것을 알 수 있으며, 이를 50% 규칙이라고 한다.
- **내부 단편화(internal fragmentation)**: 유휴 공간이 충분하지 않아 프로세스를 할당할 수 없는 경우
    - 18464B 크기의 가용공간이 있을 때, 한 프로세스가 18462B 를 요구한다. 이때 남는 공간은 2B인데, 이 공간을 활용하기 위해 오히려 2B 보다 더 큰 부담을 시스템이 가지게 될 것이다.
- **압축(compaction)**: 외부 단편화 문제를 해결하는 방법이다. 이 방법은 메모리 모든 내용을 한군데로 몰고 모든 가용 공간을 다른 한 군데로 몰아서 큰 블록을 만드는 것이다.
    - 최적 알고리즘이 없어 부담이 큰 방법이다.
    - 압축은 프로세스들의 재배치가 실행 시간에 동적으로 이루어지는 경우에만 사용 가능하다.

---

## 3. 페이징_Paging

이전까지 메모리 관리는 프로세스의 물리 주소 공간이 **연속적**이여야 했다.

페이징은 프로세스의 물리 주소 공간이 연속되지 않아도 되는 메모리 관리 기법이다. 페이징은 연속 메모리 할당을 괴롭히는 두 가지 문제인 외부 단편화와 관련 압축의 필요성을 피한다.

### 3.1 기본 방법_Basic Method

- 물리 메모리는 **프레임(frame)**이라 불리는 **같은 크기의 블록으로 나누어진다**.
- 논리 메모리는 **페이지(page)**라 불리는 **같은 크기의 블록으로 나누어 진다.**
- 프로세스가 실행될 때 그 **프로세스의 페이지**는 파일 시스템 또는 예비 저장장치로부터 가용한 **메인 메모리 프레임으로 적재**된다.

![Untitled 6](https://user-images.githubusercontent.com/75190035/176812462-9bcb333d-c7b8-4365-b614-95f786e7d7f5.png)

- CPU에서 나오는 모든 주소는 **페이지 번호**(p)와 **페이지 오프셋**(d: offset) 두 개의 부분으로 나누어 진다.
    - 페이지 번호: 페이지 테이블 인덱스 값으로 프로세스 **페이지 테이블**을 액세스할 때 사용된다.
    - 페이지 오프셋: 범위(변하지 않음)

![Untitled 7](https://user-images.githubusercontent.com/75190035/176812452-87c80a61-8fbb-41fe-bd42-294eea02f5bc.png)

- 논리 주소 → 물리 주소 변환 과정
    1. 페이지 번호 p를 추출해 페이지 테이블의 인덱스로 사용한다.
    2. 페이지 테이블에서 해당 프레임 번호 f를 추출한다.
    3. 논리 주소의 페이지 번호 p를 프레임 번호 f로 바꾼다.
    - 이때, 오프셋 d는 변하지 않기 때문에 대체되지 않으며, 프레임 번호와 오프셋은 물리 주소를 구성하게 된다.
    

![Untitled 8](https://user-images.githubusercontent.com/75190035/176812440-6a44d755-c387-49ed-bc23-c63823f10ab4.png)

- 논리 주소 공간의 크기가 2^m이고, 페이지 크기가 2^n 바이트인 경우 논리 주소의 상위 (m-n) 비트는 페이지 번호로 지정하고, 나머지 하위 n 비트는 페이지 오프셋을 지정한다.
- 페이징을 사용하면 외부 단편화는 발생하지 않지만, 대신 내부 단편화가 발생한다.
    - 만약 페이지 크기가 2,048B이고, 프로세스가 72,766B를 요구한다면 35개의 페이지 프레임을 할당하고, 1,086B가 남는다. 36번째 프레임은 2,048 - 1,086 = 962B의 내부 단편화가 발생하게 된다.
    - 때문에 작은 페이지 크기가 바람직 할 수 있지만, 그렇게되면 페이지 테이블의 크기가 커질 수 있다.
- 프로그래머는 페이징 기법으로 실제 분산되어 있는 메모리를 마치 연속적인 공간에 있는 메모리 처럼 사용할 수 있다.
- 운영체제는 물리 메모리를 관리하기 떄문에 물리 메모리의 자세한 할당에 대해 파악하고 있어야 한다.
    - 어느 프레임이 할당되어 있고, 어느 프레임이 사용 가능한지, 총 프레임은 몇개인지 등
    - 이런 정보는 일반적으로 **프레임 테이블(frame table)이라는 시스템에 하나밖에 없는 자료구조에 있다.**
- 운영체제는 모든 프로세스의 주소들을 실제 주소로 사상(mapping)할 수 있어야 한다.

### 3.2 하드웨어 지원

페이지 테이블의 하드웨어 구현은 여러 방법으로 수행할 수 있다.

- 가장 간단한 경우 페이지 테이블은 전용 고속 하드웨어 레지스터 세트로 구현될 수 있다.
    - 이 방식은 페이지 테이블이 작은 경우 적합하다.
    - 빠르지만, 각각의 레지스터가 문맥 교환 중에 교체되어야 하므로 문맥 교환 시간을 증가시킨다.
- 페이지 테이블이 큰 경우 이를 메인 메모리에 저장하고, **페이지 테이블 기준 레지스터(page-table base register, PTBR)**가 페이지 테이블을 가리키도록 한다.
    - 문맥 교환 시간을 줄일 수 있지만, 메모리 접근 시간이 늘어날 수 있다.
        - 한 번은 페이지 테이블 항목에 접근하고, 나머지 한번은 실제 데이터에 접근한다.

**3.2.1 Translation Look-Asid Buffer(TLB)**

![Untitled 9](https://user-images.githubusercontent.com/75190035/176812424-21fbd0c5-a6a8-412d-ad7d-417555880a23.png)

- 위 두 방식 모두 단점을 가지고 있다. 이런 문제 해결에 **TLB**라고 불리는 특수한 소형 하드웨어 캐시가 사용된다.
- TLB는 매우 빠른 연관 메모리로 구성된다. TLB내의 각 항목은 키와 값의 두 부분으로 구성된다.
- TLB에 페이지를 찾아달라는 요청이 들어오면, 찾고자하는 페이지를 동시에 여러 개의 내부 키와 비교한다. 발견된다면, 그에 대응하는 프레임 번호를 알려준다.
- 접근하려는 메모리의 페이지 번호가 TLB에서 발견되는 비율을 적중률(hit ratio)이라고 부른다.
- **실질 메모리 접근 시간(effective memory access time)** 계산
    - 실질 접근 시간 = 적중률 x 메모리 접근 시간(TLB에서 찾았을 때) + (1 - 적중률) x 메모리 접근 시간(TLB에서 찾지 못했을 때)
    - 메인 메모리에 접근하는데 10ns 가 걸렸을 경우
        - TLB에서 찾았으면 원하는 데이터에 접근하는 데 총 10ns가 소요된다.
        - TLB에서 찾지못했으면, 페이지 테이블에 접근해 프레임 번호를 알아내고(10ns), 원하는 데이터를 메모리에서 읽어야 한다(10ns). 따라서, 총 20ns가 소요된다.
        - 적중률 80%에서 실질 메모리 접근 시간 = 0.8 * 10 + 0.2 * 20 = 12 ns

### 3.3 보호_Protection

- 페이징 환경에서 메모리 보호는 각 페이지에 붙어있는 보호 비트에 의해 구현된다. 이 비트들은 보통 페이지 테이블에 속해 있다.
- 각 비트는 이 페이지가 읽고/쓰기 또는 읽기 전용임을 각각 정의할 수 있다.
- 메모리에 대한 접근은 페이지 테이블을 거치므로, 이때 주소 변환과 함께 이 페이지에 쓰기가 허용되는지 검사할 수 있다.
- 페이지 테이블의 각 엔트리에는 유효/무효(valid/invalid)라는 비트가 하나 더 있다.
    - 이 비트가 유효로 설정되면 관련된 페이지가 프로세스의 합법적인 페이지임을 나타낸다.
    - 이 비트가 무효로 설정되면 그 페이지는 프로세스의 논리 주소 공간에 속하지 않는다는 것을 나타낸다.
- 몇몇 시스템은 테이블의 크기를 나타내기 위해 페이지 테이블 길이 레지스터(PTLR)라는 레지스터를 제공한다.
- 프로세스가 제시한 주소가 유효한 범위 내에 있는지를 확인하기 위해 모든 논리 주소 값이 PTLR 값과 비교된다.

### 3.4 공유 페이지_Shared Pages

- 페이징의 장점은 공통의 코드를 공유할 수 있다는 점이다.
- 재진입 코드 자체는 자체 수정을 할 수 없는 코드로 실행 중에는 절대 변경되지 않는다. 따라서 두 개 이상의 프로세스가 동일한 코드를 동시에 실행할 수 있다.

---

## 4. 페이지 테이블 구조_Structure of the Page Table

### 4.1 계층적 페이징_Hierarchical Paging

![Untitled 10](https://user-images.githubusercontent.com/75190035/177000446-66c4d3c6-a4dd-44f1-9891-37641d927e10.png)

- 현대 컴퓨터는 매우 큰 주소 공간(2^32~2^64)을 가지며, 이러한 환경에서는 페이지 테이블도 상당히 커진다.
- 한 시스템에서 페이지의 크기가 4KB(2^12)라면, 페이지 테이블은 100만(2^20 = 2^32/2^12)개 이상의 항목으로 구성될 것이다. 각 항목은 다시 4B로 구성되기 때문에 각 프로세스는 페이지 테이블 만으로 4MB의 공간이 필요하게 될 것이다.
- 이러한 경우 모든 페이지 테이블을 메인 메모리에서 연속적으로 할당하기기 보다는페이지 테이블을 여러 개의 작은 조각으로 나누는 방법을 사용할 수 있다. 이 방법도 여러 방법이 있다.
- 대표적인 방법 중 하나는 **2단계 페이징 기법(two-level paging scheme)**으로 페이지 테이블 자체가 다시 페이징되게 하는 것이다.

**예시**

페이지 크기가 4KB인 시스템의 예를 들어보자.

![Untitled 11](https://user-images.githubusercontent.com/75190035/177000451-9d68726f-d85e-4817-8172-b4c11385187e.png)

이 경우 논리 주소는 20비트짜리 페이지 번호와 12비트짜리 오프셋으로 이루어진다.

페이지 테이블도 페이지로 나누어지기 때문에 페이지 번호는 다시 10비트짜리 페이지 번호와 10비트짜리 페이지 오프셋으로 나누어진다.

p1은 바깥 페이지 테이블의 인덱스, p2는 안쪽 페이지 테이블의 페이지 내의 오프셋이다.

![Untitled 12](https://user-images.githubusercontent.com/75190035/177000453-be445f2d-87f6-47db-b7c4-eb452b8e0e91.png)

이 처럼 주소 변환이 바깥 페이지 테이블에서 시작해 안쪽으로 들어오는 방식을 **forward-mapped 페이지 테이블**이라고 한다.

### 4.2 해시 페이지 테이블_Hashed Page Tables

![Untitled 13](https://user-images.githubusercontent.com/75190035/177000454-f94649e5-f802-4219-91d8-fd54a0b0e081.png)

- 주소 공간이 32비트보다 커지면 가상 주소를 해시로 사용하는 **해시 페이지 테이블**을 많이 사용한다.
- 해시 페이지 테이블의 각 항목은 연결 리스트를 가지고 있다. 이곳에는 충돌을 일으켜서 모두 이곳으로 해시되는 원소들이 매달리게 된다.
- 각 원소는 세 개의 필드를 가진다.
    1. 가상 페이지 번호
    2. 사상되는 페이지 프레임 번호
    3. 연결 리스트상의 다음 원소 포인터
- 여기서는 알고리즘이 다음과 같이 작동된다.
    1. 가상 주소 공간으로부터 페이지 번호가 오면 그것을 해싱한다.
    2. 그 값으로 해시 페이지 테이블에서 연결 리스트를 따라가며 첫 번째 원소와 가상 페이지 번호를 비교해 본다.
    3. 
        1. 일치되면 그에 대응하는 페이지 프레임 번호를 가져와 물리 주소를 얻는다.
        2. 일치되지 않으면 연결 리스트의 다음 원소로 똑같은 일을 반복한다.

### 4.3 역 페이지 테이블_Inverted Page Table

- 운영체제는 프로세스가 가상 페이지 주소를 제시할 때마다 이 테이블에 와서 그것을 실제 페이지 주소로 변환시켜 주어야 한다.
- 테이블은 가상 주소에 대해 오름차순으로 정렬되어 있고 운영체제는 테이블 내의 어느 곳에 원하는 물리 페이지가 있는지 계산할 수 있고, 이 값을 통해서 메모리를 액세스 할 수 있다.
- 이 기법의 단점 중 하나는 페이지 테이블 항목의 개수가 수백만 개가 될 수 있다는 것이다. 이러한 테이블은 물리 메모리의 사용을 추적하기 위해 많은 양의 메모리를 소비한다.
- 이 단점을 해결하는 한 방법이 **역 페이지 테이블(inverted page table)**이다.

![Untitled 14](https://user-images.githubusercontent.com/75190035/177000458-92a4bb97-fcec-41b8-b21b-1ca035804af9.png)

- 역 페이지 테이블에서는 메모리 프레임마다 한 항목씩을 할당한다. 각 항목은 그 프레임에 올라와 있는 페이지 주소, 그리고 그 페이지를 소유하고 있는 프로세스의 ID를 표시한다.
- 이렇게 되면 시스템에는 단 하나의 페이지 테이블만이 존재하게 되고, 테이블 내 각 항목은 메모리 한 프레임씩을 가리키게 된다.

---

## 5. 스와핑_Swapping

프로세스가 실행되기 위해서는 프로세스의 명령어와 명령어가 접근하는 데이터가 메모리에 있어야 한다. 그러나 프로세스 또는 프로세스의 일부분은 실행 중에 임시로 백업 저장장치(backing stroe)로 보내졌다가 실행을 계속하기 위해 메모리로 되돌아 올 수도 있다.

모든 프로세스의 물리 주소 공간의 크기가 총합이 시스템의 실제 물리 메모리 크기보다 큰 경우에도 스와핑을 이용하면 동시에 실행하는 것이 가능하여 다중 프로그래밍 정도를 증가시킨다.

### 5.1 기본 스와핑_Standard Swapping

![Untitled 15](https://user-images.githubusercontent.com/75190035/177031078-0a1cd63a-d10e-4fbd-b80a-2b96b1648b01.png)

- 표준 스와핑에는 메인 메모리와 백업 자장장치 간에 전체 프로세스를 이동시킨다.
    - 백업 저장장치는 보통 빠른 보조저장장치다.
    - 백업 저장장치는 저장 및 다시 접근해야 하는 프로세스의 크기에 상관없기 수용할 수 있을 만큼 커야하며, 메모리에 직접 액세스할 수 있어야 한다.
- 프로세스 또는 일부가 백업 자장장치로 스왑될 때 프로세스와 관련된 자료구조는 백업 저장장치에 기록되어야 한다.
    - 다중 스레드 프로세스의 경우 모든 스레드당 데이터 구조도 스왑되어야 한다.
- 운영체제는 스왑아웃된 프로세스에 대한 메타데이터를 유지해야 다시 스왑인될 때 복원될 수 있다.
- 장점
    - 실제 물리 메모리보다 더 많은 프로세스를 수용할 수 있도록 물리 메모리가 초과 할당될 수 있다.
- 유휴 또는 대부분의 시간을 유휴 상태로 보내는 프로세스가 스와핑에 적합한 후보다.

### 5.2 페이징에서의 스와핑_Swapping in Paging

![Untitled 16](https://user-images.githubusercontent.com/75190035/177031076-6db7b1de-1c72-4388-a0f8-4cbe78305da0.png)

- 표준 스와핑은 메모리와 백업 자장장치 간에 프로세스 전체를 이동하는데 걸리는 시간이 엄청나기 때문에 최신 운영체제에서는 잘 사용하지 않는다.
- 대부분의 시스템은 프로세스 전체가 아닌 프로세스 페이지를 스왑할 수 있는 변형 스와핑을 사용한다.
- 이 전력은 여전히 물리 메모리를 초과 할당할 수 있지만 프로세스 전체를 스왑하는 비용은 발생하지 않는다.
- 연산
    - 페이지-아웃: 페이지를 메모리에서 백업 자장장치로 이동시킨다.
    - 페이지-인: 페이지를 백업 저장장치에서 메모리로 이동시킨다.

---

> 참고
> 
> - 책
> 
> [⌜Operating System Concepts 10th - Abraham Silberschatz, Peter B. Galvin, Greg Gagne⌟](http://www.yes24.com/Product/Goods/78225791)
> 
> - 블로그
> 
> [https://will-behappy.tistory.com/24?category=808600](https://will-behappy.tistory.com/24?category=808600)
>
