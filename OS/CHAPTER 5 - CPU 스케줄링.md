# CHAPTER 5 - CPU 스케줄링

## 1. 기본 개념_Basic Concepts

다중 프로그래밍의 목적은 CPU 이용률을 최대화하기 위해 항상 실행 중인 프로세스를 가지게 하는 데 있다.

### 1.1 CPU-I/O 버스트 사이클_CPU-I/O Burst Cycle

<img width="296" alt="Untitled" src="https://user-images.githubusercontent.com/75190035/175017429-cc8686b9-9aa8-475c-bcc2-a7176985f84c.png">

- 프로세스 실행은 CPU 실행과 I/O 대기의 사이클로 구성된다. 프로세스들은 이들 두 상태 사이를 교대로 왔다 갔다 한다.
- 프로세스 실행은 CPU 버스트로 시작되고, 뒤이어 I/O 버스트가 발생한다. 그 뒤로 이 사이클이 반복된다.
- 마지막 CPU 버스트는 I/O 버스트가 뒤따르는 대신, 실행을 종료하기 위한 시스템 요청과 함께 끝난다.

### 1.2 CPU 스케줄러_CPU Scheduler

- CPU가 유휴 상태가 될 때마다, 운영체제는 준비 큐에 있는 프로세스 중에서 하나를 선택해 실행해야 한다.
- 이때, 선택 절차가 CPU 스케줄러에 의해 실행된다.
- 스케줄러는 실행 준비 되어 있는 메모리 내의 프로세스 중 하나를 선택해 CPU를 할당한다.
    - 준비 큐는 FIFO 방식이 아니어도 된다.(선입선출 큐, 우선순위 큐 또는 단순히 순서가 없는 연결 리스트로 구현할 수 있다.)

### 1.3 선점 및 비선점 스케줄링_Preemptive and Nonpreemptive Scheduling

- CPU 스케줄링 결정은 다음 4 가지 상황에서 발생할 수 있다.
    1. 한 프로세스가 실행 상태에서 대기 상태로 전환될 때
    2. 프로세스가 실행 상태에서 준비 완료 상태로 전환될 때
    3. 프로세스가 대기 상태에서 준비 완료 상태로 전환될 때
    4. 프로세스가 종료할 때
- 상황 1과 4의 경우, 스케줄링 면에서는 선택의 여지가 없으며, 실행을 위해 새로운 프로세스가 반드시 선택되어야 한다. 상황 2와 3의 경우 선택의 여지가 있다.
- 상황 1, 4에서만 스케줄링이 발생할 경우, 우리는 이러한 스케줄링 방법을 비선점(nonpreemptive) 또는 협조적(cooperative)이라고 하고, 그렇지 않으면 선점(preemptive)이라고 한다.
- **비선점**
    - CPU가 한 프로세스에게 할당되면 프로세스가 종료하든지, 또는 대기 상태로 전환해 CPU를 방출할 때까지 점유한다.
- **선점**
    - 한 프로세스가 CPU를 할당받아 실행중이라도 다른 프로세스가 현재 프로세스를 중지 시키고 CPU를 강제적으로 뺏을 수 있다.
    - 데이터가 다수의 프로세스에 의해 공유될 때 경쟁 조건을 초래할 수 있다.

### 1.4 디스패처_DIspatcher

<img width="195" alt="Untitled 1" src="https://user-images.githubusercontent.com/75190035/175017458-ef6bdab1-1a5c-485a-9d1e-7539ba429918.png">

- 디스패처는 CPU 코어의 제어를 CPU 스케줄러가 선택한 프로세스에 주는 모듈이며 다음과 같은 작업을 포함한다.
    - 한 프로세스에서 다른 프로세스로 문맥을 교환하는 일
    - 사용자 모드로 전환하는 일
    - 프로그램을 다시 시작하기 위해 사용자 프로그램의 적절한 위치로 이동(jump)하는 일
- 디스패처는 모든 프로세스의 문맥 교환 시 호출되므로, 가능한 최고로 빨리 수행되어야 한다.
- 디스패처가 하나의 프로세스를 정지하고 다른 프로세스의 수행을 시작하는 데까지 소요되는 시간을 디스패치 지연(dispatch latency)라고 한다.

---

## 2. 스케줄링 기준_Scheduling Criteria

CPU 스케줄링 알고리즘을 비교하기 위한 여러 기준

- CPU 이용률(utilization)
    - 가능한 한 CPU를 최대한 바쁘게 유지하기를 원한다.
    - 실제 시스템에서는 40%(부하가 적은 시스템의 경우)~90%(부하가 큰 시스템의 경우) 범위를 가져야 한다.
- 처리량(throughput)
    - 작업량 측정의 한 방법으로, 단위 시간당 완료된 프로세스의 개수를 처리량이라고 한다.
- 총 처리 시간(turnaround time)
    - 특정한 프로세스의 입장에서 중요한 기준은 그 프로세스를 실행하는 데 소요된 시간이다.
    - 프로세스의 제출 시간과 완료 시간의 간격을 총 처리 시간이라 한다.
    - 총 처리 시간은 준비 큐에서 대기한 시간, CPU에서 실행하는 시간, I/O 시간을 합한 시간이다.
- 대기 시간(waiting time)
    - CPU 스케줄링 알고리즘은 프로세스가 실행하거나 I/O을 하는 시간의 양에 영향을 미치지 않는다. 단지 프로세스가 준비 큐에서 대기하는 시간의 양에만 영향을 준다.
    - 준비 큐에서 대기하면서 보낸 시간의 합을 대기 시간이라 한다.
- 응답 시간(response time)
    - 대화식 시스템(interactive system)에서 총 처리 시간은 최선의 기준이 아닐 수 있다. 프로세스가 어떤 출력을 일찍 생성하고, 앞서의 결과가 출력되는 사이 새 결과를 얻으려고 연산을 계속하는 경우가 있다.
    - 하나의 요구를 제출한 후 첫 번째 응답이 나올 때까지의 시간을 응답 시간이라 한다.
    - 응답 시간은 응답이 시작되는 데까지 걸리는 시간이지, 그 응답을 출력하는 데 걸리는 시간은 아니다.

---

## 3. 스케줄링 알고리즘_Scheduling Algorithms

CPU 스케줄링은 준비 큐에 있는 프로세스 중 어느 프로세스에 CPU 코어를 할당할 것인지를 결정하는 문제를 다룬다.

### 3.1 선입 선처리 스케줄링_First-Served Scheduling

- 가장간단한 CPU 스케줄링 알고리즘(비선점)
- CPU를 가장 먼저 요청하는 프로세스가 CPU를 먼저 할당받는다.
- 선입 선처리 정책의 구현은 선입선출(FIFO) 큐로 쉽게 관리할 수 있고, 프로세스가 준비 큐에 진입하면 이 프로세스의 프로세스 제어 블록(PCB)을 큐의 끝에 연결한다.
- CPU가 가용 상태가 되면, 준비 큐의 앞부분에 있는 프로세스에 할당되고, 해당 프로세스는 준비 큐에서 제거된다.
- 장점
    - 선입 선처리를 위한 코드는 작성하기 쉽고 이해하기 쉽다.
- 단점
    - 선입 선처리 정책하에서 평균대기 시간은 일반적으로 최소가 아니며, 프로세스 CPU 버스트 시간이 크게 변할 경우에는 평균대기 시간도 상당히 변할 수 있다.

다음과 같은 프로세스들이 대기 큐에 있다고 가정해보자.

| 프로세스 | 버스트 시간(ms) |
| --- | --- |
| P1 | 24 |
| P2 | 3 |
| P3 | 3 |

선입 선처리 알고리즘은 들어온 순서대로 CPU를 할당하므로, 다음 그림과 같을 것이다.

<img width="463" alt="Untitled 2" src="https://user-images.githubusercontent.com/75190035/175017475-008f80ba-0e6a-41ce-b12c-2b1ba9d6c847.png">

이때, 평균 대기 시간은 17ms 정도로 최소가 아니다.

이렇게 모든 프로세스들이 하나의 긴 프로세스가 CPU를 양도하기를 기다리는 것을 **호위 효과(convoy effect)**라고 한다.

### 3.2 최단 작업 우선 스케줄링_Shortest-Job-First Scheduling(SJF)

- 이 알고리즘은 각 프로세스에 다음 CPU 버스트 길이를 연관시킨다.(선점형이거나 비선점형)
- CPU 이용이 가능해지면, 가장 작은 다음 CPU 버스트를 가진 프로세스에 할당한다. 만약 같은 길이를 가질 때는 선입 선처리 스케줄링을 적용한다.
- 장점
    - 최단 작업 우선 스케줄링은 주어진 프로세스 집합에 대해 최소의 평균 대기시간을 가진다는 점에서 최적임을 증명할 수 있다.
- 단점
    - 최단 작업 우선 스케줄링은 최적이긴 하지만, CPU 버스트 길이를 알 방법이 없기 때문에 CPU 스케줄링 수준에서는 구현할 수 없다. 즉, 비현실적이다.
- **도착 시간을 고려하지 않은** **최단 작업 우선 스케줄링(비선점형)**

다음과 같은 프로세스들이 준비 큐에 있다고 가정해 보자. 비선점형일 경우 결과는 다음과 같다.

| 프로세스 | 버스트 시간(ms) |
| --- | --- |
| P1 | 6 |
| P2 | 8 |
| P3 | 7 |
| P4 | 3 |

최단 작업 우선 스케줄링을 이용하면 가장 작은 버스트 시간을 기준으로 CPU 를 할당하기 때문에 다음의 그림과 같다.

<img width="471" alt="Untitled 3" src="https://user-images.githubusercontent.com/75190035/175017487-67839583-03f3-4080-85f5-80140f421642.png">

이때, 평균 대기시간은 9ms이고, 최소의 평균 대기시간을 가진다.

- **도착시간을 고려한** **최단 작업 우선 스케줄링(선점형)**

다음과 같은 프로세스들이 준비 큐에 있다고 가정해 보자. 선점형일 경우 결과는 다음과 같다.

| 프로세스 | 도착시간(ms) | 버스트 시간(ms) |
| --- | --- | --- |
| P1 | 0 | 6 |
| P2 | 1 | 8 |
| P3 | 2 | 7 |
| P4 | 3 | 3 |

프로세스가 도착할 때 새로운 선택이 발생한다. 새로운 프로세스가 현재 실행되고 있는 프로세스의 남은 시간보다도 더 짧은 CPU 버스트를 가진다면 새로운 프로세스에 CPU를 할당한다.

만약 비선점형이라면, 현재 실행하고 있는 프로세스가 끝날 때 까지 기다려야 하므로 동작 방식이 다르다.

<img width="467" alt="Untitled 4" src="https://user-images.githubusercontent.com/75190035/175017495-2a59c535-e013-46d5-bba6-6d0329ee1432.png">

이때, 평균 대기시간은 6.5ms이다.

### 3.3 라운드 로빈 스케줄링_Round-Robin Scheduling

- 이 알고리즘은 선입 선처리 스케줄링과 유사하지만 시스템이 프로세스들 사이를 옮겨다닐 수 있도록 선점이 추가된다.(선점형)
    - 시간 할당량 또는 타임슬라이스라고 하는 작은 단위의 시간을 정의한다.
    - 시간 할당량은 일반적으로 10~100ms 동안이다.
- CPU 스케줄러는 준비 큐를 돌면서 한 번에 한 프로세스에 한 번의 시간 할당량 동안 CPU를 할당한다.
- 프로세스의 CPU 버스트가 시간 할당량보다 작을 경우, 프로세스 자신이 CPU를 자발적으로 방출할 것이다. 그 후 준비 큐에 있는 다음 프로세스가 CPU를 할당받는다.
- 프로세스의 CPU 버스트가 시간 할당량보다 긴 경우, 타이머가 끝나고 운영체제에 인터럽트를 발생한다. 문맥 교환이 일어나고, 실행하던 프로세스는 준비 큐의 꼬리에 넣어진다. 그 후 준비 큐에 다음 프로세스가 CPU를 할당받는다.
- 특징
    - 시간 할당량의 크기에 매우 많은 영향을 받는다. 시간 할당량이 매우 크다면 선입 선처리 정책과 같다.
    - 시간 할당량이 매우 작다면 매우 많은 문맥 교환을 야기하므로 프로세스의 실행이 느려진다.
    - 따라서 시간 할당량이 문맥 교환 시간과 비교해 더 클 것을 요구한다.

다음과 같은 프로세스들이 준비 큐에 있다고 가정해 보자. (할당 시간=4ms)

| 프로세스 | 버스트 시간(ms) |
| --- | --- |
| P1 | 24 |
| P2 | 3 |
| P3 | 3 |

라운드 로빈 알고리즘은 들어온 순서대로 CPU를 할당하고, 할당 시간이 끝나면 다음 프로세스에 CPU를 할당하므로 결과는 다음과 같다.

<img width="473" alt="Untitled 5" src="https://user-images.githubusercontent.com/75190035/175017512-345851d8-966c-4ca9-8f13-2d87cc83602c.png">

이때, 평균 대기시간은 5.66ms다.

---

### 3.4 우선순위 스케줄링_Priority Scheduling

- 최단시간 우선 스케줄링은 일반적인 우선순위 스케줄링 알고리즘의 특별한 경우다.(선점형 or 비선점형)
- 우선순위가 각 프로세스들에 연관되어 있으며, CPU는 가장 높은 우선순위를 가진 프로세스에 할당된다. 우선순위가 같은 프로세스들은 선입 선처리 순서로 스케줄링 된다.
- 우선순위는 내부적 또는 외부적으로 정의될 수 있다.
    - 내부적인 경우, 프로세스의 우선순위를 계산하기 위해 어떤 측정 가능한 양들을 사용한다.
        - 시간 제한, 메모리 요구, 열린 파일의 수, 평균 I/O 버스트의 평균 CPU 버스트에 대한 비율 등
    - 외부적인 경우 운영체제 외부적 기준에 의해 결정된다.
        - 프로세스의 중요성, 컴퓨터 사용을 위해 지불되는 비용의 유형과 양, 그 작업을 후원하는 부서 그리고 정치적 요인 등
- 문제점
    - 무한 봉쇄(indefinite blocking), 기아 상태(starvation)
        - 우선순위 스케줄링 알고리즘을 사용할 경우 낮은 우선순위 프로세스들이 CPU를 무한히 대기하는 경우가 발생한다.
        - 높은 우선순위의 프로세스들이 꾸준히 들어와서 낮은 우선순위의 프로세스들이 CPU를 얻지 못하게 될 수도 있다.
    - 프로세스가 결국 실행되거나 컴퓨터 시스템이 결국 크래시하여 아직 끝나지 않은 우선순위가 낮은 프로세스들을 잃어버린다.
- 해결책
    - 노화(aging)
        - 노화는 오랫동안 시스템에서 대기하는 프로세스들의 우선순위를 점진적으로 증가시킨다.
    - 라운드 로빈과 우선순위 스케줄링의 결합
        - 시스템이 우선순위가 가장 높은 순서대로 실행하되, 우선순위가 같은 프로세스들은 라운드 로빈 스케줄링을 사용한다.

다음과 같은 프로세스들이 준비 큐에 있다고 가정해 보자. (우선순위 숫자가 낮을 수록 우선순위가 높다고 가정)

| 프로세스 | 버스트 시간(ms) | 우선 순위 |
| --- | --- | --- |
| P1 | 10 | 3 |
| P2 | 1 | 1 |
| P3 | 2 | 4 |
| P4 | 1 | 5 |
| P5 | 5 | 2 |

우선순위 스케줄링은 우선순위에 따라 CPU를 할당하기 때문에 결과는 다음과 같다.

<img width="472" alt="Untitled 6" src="https://user-images.githubusercontent.com/75190035/175017531-991ee82e-a131-4a11-a2bf-3654790c447b.png">

이때, 평균 대기시간은 8.2ms다.

### 3.5 다단계 큐 스케줄링_Multilevel Queue Scheduling

- 우선순위와 라운드 로빈은 스케줄링을 사용할 때 모든 프로세스가 단일 큐에 배치되고 스케줄러는 우선순위가 가장 높은 프로세스를 선택하여 실행할 수 있다. 이때, 우선순위 검색을 위해 O(n) 검색이 필요할 수 있다.
- 다단계 큐 방식은 우선순위 혹은 프로세스 유형에 따라 별도의 큐를 갖게하는 방법이다.
- 각 큐에는 자체 스케줄링 알고리즘이 있을 수 있다.
- 큐와 큐 사이에 스케줄링도 반드시 있어야 한다. 일밙거으로 고정 우선순위의 선점형 스케줄링으로 구현된다.

### 3.6 다단계 피드백 큐 스케줄링_Multilevel Feedback Queue Scheduling

- 다단계 큐 스케줄링 알고리즘에서는 일반적으로 프로세스들이 시스템 진입 시에 영구적으로 하나의 큐에 할당된다.
- 다단계 피드백 큐 스케줄링에서는 프로세스가 큐들 사이를 이동하는 것을 허용한다.
- 예)
    - 어떤 큐가 CPU 시간을 너무 많이 사용하면, 우선순위가 낮은 큐로 이동한다.
    - 어떤 큐가 낮은 우선순위 큐에서 너무 오래 대기하는 프로세스는 높은 우선순위 큐로 이동할 수 있다.
    - 이런 형태로 기아 상태를 예방한다.

---

## 4. 스레드 스케줄링_Thread Scheduling

대부분 최신 운영체제에서 스케줄 되는 대상은 프로세스가 아닌 커널 수준 스레드다.

### 4.1 경쟁 범위_Contention Scope

- 동일한 프로세스에 속한 스레드들 사이에서 CPU를 경쟁하면, 프로세스-경쟁-범위(PCS)라 한다.
- CPU상에서 어느 커널 스레드를 스케줄 할 것인지 결정하기 위해서 커널은 시스템-경쟁-범위(SCS)를 사용한다.

---

## 5. 다중 처리기 스케줄링_Multiple-Processor Scheduling

만일 여러 CPU가 사용 가능하다면, 여러 스레드가 병렬로 실행될 수 있으므로 부하 공유(load sharing이 가능해지지만, 스케줄링 문제는 그에 상응해 더 복잡해진다.

### 5.1 다중 처리기 스케줄링에 대한 접근 방법

- 비대칭 다중 처리(asymmetric multiprocessing)
    - 다중 처리기 시스템의 CPU 스케줄링에 관한 한 가지 해결 방법은 마스터 서버라는 하나의 처리기가 모든 스케줄링 결정과 I/O 처리 그리고 다른 시스템의 활동을 취급하게 되는 것이다.
        
        다른 처리기들은 사용자 코드만을 수행한다. 이러한 비대칭 다중 처리는 오직 하나의 코어만 시스템 자료구조에 접근해 자료 공유의 필요성을 배제하기 때문에 간단하다.
        
    - 단점은 마스터 서버가 전체 시스템 성능을 저하할 수 있는 병목이 된다는 것이다.
- 대칭 다중 처리(symmetric multiprocessing)
    - 다중 처리기를 지원하기 위한 표준 접근 방식이다.
    - 각 프로세서는 스스로 스케줄링 할 수 있다. 각 프로세서의 스케줄러가 준비 큐를 검사하고 실행할 스레드를 선택하여 스케줄링이 진행된다.

### 5.2 다중 코어 프로세서_Multicore Processors

- 현대 컴퓨터 하드웨어는 동일한 물리적인 칩 안에 여러 개의 처리 코어를 장착하여 다중 코어 프로세서(multicore processor)가 된다.
- 각 코어는 구조적인 상태를 유지하고 있어서 운영체제 입장에서는 개별적인 논리적 CPU처럼 보이게 된다.
- 다중 코어 프로세서를 사용하는 SMP 시스템은 CPU가 자신의 물리 칩을 가지는 시스템에 비해 속도가 빠르고 적은 전력을 소모한다.
- 다중 코어 프로세서는 스케줄링 문제를 복잡하게 한다.
    - 프로세서가 메모리에 접근할 때 데이터가 가용해지기를 기다리면서 많은 시간을 허비한다.
    - 이 상황을 메모리 스톨(memory stall)이라고 하며, 프로세서가 메모리보다 빠른 속도로 동작해 발생한다.
    - 혹은, 캐시 미스(캐시 메모리가 없는 데이터를 엑세스)로 인해 메모리 스톨이 발생할 수도 있다.

<img width="462" alt="Untitled 7" src="https://user-images.githubusercontent.com/75190035/175017550-64c06305-a26f-4d8f-8bf8-48f54153c330.png">

- 메모리 스톨을 해결하기 위해 많은 하드웨어 설계는 다중 스레드 처리 코어를 구현한다.
    - 이 설계에서 하나의 코어에 2개 이상의 하드웨어 스레드가 할당된다. 이렇게 하면 메모리를 기다리는 동안 하나의 하드웨어 스레드가 중단되면 코어가 다른 스레드로 전환할 수 있다.

<img width="472" alt="Untitled 8" src="https://user-images.githubusercontent.com/75190035/175017554-25c2b332-6f04-492a-847c-43613ad1e3be.png">

### 5.3 부하 균등화_Load Balancing

- 처리기가 하나 이상이라는 것을 최대한 활용하려면, 부하를 모든 처리기에 균등하게 배분하는 것이 중요하다.
- 부하 균등화는 시스템의 모든 처리기 사이에 부하가 고르게 배분되도록 시도한다. 통상 각 처리기가 실행할 스레드를 위한 자기 자신만의 준비 큐를 가지고 있는 시스템에서만 필요한 기능이다.
- 부하 균등화를 위해서는 두 가지 일반적인 접근 법이 있다.
    - push 이주
        - 특정 태스크가 주기적으로 각 처리기의 부하를 검사하고 만일 불균형 상태로 밝혀지면 과부하인 처리기에서 쉬고 있거나 덜 바쁜 처리기로 스레드를 이동시킴으로써 **부하를 분배한다**.
    - pull 이주
        - 쉬고있는 처리기가 바쁜 처리기를 기다리고 있는 프로세스를 pull 할 때 일어난다.
    - 두 방식은 상호 배타적일 필요는 없으며 실제로는 종종 병렬적으로 구현된다.
- 균등 부하의 개념은 두 가지 관점을 가질 수 있다.
    - 모든 큐에 대략 같은 수의 스레드가 있어야 한다.
    - 균등이란 모든 큐에 스레드 우선순위를 균등하게 분배해야 한다.

---

## 6. 실시간 CPU 스케줄링_Real-Time CPU Scheduling

실시간 운영체제에서 CPU를 스케줄링 할 때는 특별한 쟁점을 고려해야 한다.

일반적으로 연성 실시간 시스템과 경성 실시간 시스템으로 구분한다. 

- 연성 실시간 시스템
    - 중요한 실시간 프로세스가 스케줄 되는 시점에 관해 아무런 보장을 하지 않는다.
- 경성 실시간 시스템
    - 더 엄격한 요구 조건을 만족시켜야 한다.
    - 태스크는 반드시 마감시간까지 서비스를 받아야 하며 마감시간이 지난 이후에 서비스를 받는 것은 서비스를 전혀 받지 않는 것과 동일한 결과를 낳는다.

### 6.1 지연시간 최소화_Minimizing Latency

- 시스템은 일적으로 실시간으로 발생하는 이벤트를 기다린다.
- 이벤트는 타이머가 만료되었을 때처럼 소프트웨어적으로 발생하기도 하고, 원격으로 제어되던 장치가 방해물을 만났을 때 처럼 하드웨어적으로 발생하기도 한다.
- 이벤트 지연시간(event latency)는 이벤트가 발생해서 그에 맞는 서비스가 수행될 때까지의 시간을 말한다.
- 실시간 시스템의 성능은 다음 두 가지 유형의 지연시간이 좌우한다.
    1. 인터럽트 지연시간
        - CPU에 인터럽트가 발생한 시점부터 해당 인터럽트 처리 루틴이 시작하기까지의 시간
    2. 디스패치 지연시간
        - 스케줄링 디스패처가 하나의 프로세스를 블록시키고 다른 프로세스를 시작하는 데까지 걸리는 시간

### 6.2 우선순위 기반 스케줄링_Priority-Based Scheduling

- 실시간 운영체제에서 가장 중요한 기능은 실시간 프로세스에 CPU가 필요할 때 바로 응답해 주는 것이다.
- 따라서 실시간 운영체제의 스케줄러는 선점을 이용한 우선순위 기반의 알고리즘을 지원해야만 한다.
- 우선순위 기반의 스케줄링 알고리즘은 각각의 프로세스의 중요성에 따라서 그 우선순위를 부여한다. 더 중요한 태스크가 그렇지 않은 태스크들보다 더 높은 우선순위를 갖게 된다.
- 스케줄러가 선점 기법을 제공한다면, 현재 CPU를 점유하고 있는 프로세스가 더 높은 우선순위를 갖는 프로세스에 선점 될 수 있다.

### 6.3 Rate-Monotonic 스케줄링_Rate-Monotonic Scheduling

- Rate-Monotonic 스케줄링 알고리즘은 선점 가능한 정적 우선순위 정책을 이용해 주기 태스크들을 스케줄 한다.
- 낮은 우선순위 프로그램이 실행 중이고 더 높은 우선순위의 프로세스가 실행 준비가 되면, 높은 우선순위의 프로세스가 낮은 우선순위의 프로세스를 선점한다.
- 각각의 주기 태스크들은 시스템에 진입하게 되면 주기에 따라서 우선순위가 정해진다.
- 주기가 짧은 태스크는 높은 우선순위가, 주기가 긴 태스크는 낮은 우선순위가 배정된다.
- 이 정책은 CPU를 더 자주 필요로 하는 태스크에 더 높은 우선순위를 주려는 원리에 기반을 두고 있다.

프로세스들이 다음과 같은 주기와 수행 시간을 갖는다고 가정한다.

| 프로세스 | 주기 | 수행 시간 |
| --- | --- | --- |
| P1 | 50 | 20 |
| P2 | 100 | 35 |

만약 P2가 P1 보다 높은 우선순위를 갖는다면 다음 결과와 같이 마감시간을 지키지 못한다.(마감시간은 다음 주기가 시작하기 전까지이다.)

<img width="418" alt="Untitled 9" src="https://user-images.githubusercontent.com/75190035/175017565-48db0739-48dd-4ed4-87df-44fef6ed9722.png">

Rate-Monotonic 스케줄링은 주기가 짧은 태스크가 높은 우선순위를 부여받으므로, P1이 P2 보다 먼저 실행되게 된다. 결과는 다음과 같다.

<img width="465" alt="Untitled 10" src="https://user-images.githubusercontent.com/75190035/175017579-9af557c6-392f-4f79-b4f8-941f7e7f1146.png">

Rate-Monotonic 스케줄링을 사용한 결과에서 마감시간을 지킬 수 있다.

Rate-Monotonic 스케줄링 기법이 스케줄 할 수 없는 프로세스 집합의 경우 정적 우선순위를 이용하는 다른 알고리즘들 역시 스케줄할 수 없는 측면에서 최적이라고 할 수 있다.

- 단점(제약)
    - CPU 이용률은 한계가 있기 때문에 CPU 자원을 최대화해서 사용하는 것은 불가능 하다.
    - 시스템에 한 개의 프로세스만 존재할 때, CPU 이용률은 100% 지만 최소 69%까지 떨어진다.

### 6.4 Earliest-Deadline-First 스케줄링_Earliest-Deadline-First Scheduling

- EDF 스케줄링 기법은 마감시간에 따라서 우선순위를 동적으로 부여한다.
- 마감시간이 가까워질 수록 우선순위는 높아지고, 멀 수록 낮아진다.
- EDF 정책에서 프로세스가 실행 가능하게 되면 자신의 마감시간을 시스템에 알려야 한다. 우선순위는 새로 실행 가능하게 된 프로세스의 마감시간에 맞춰서 다시 조정된다.
- 우선순위가 동적이라는 점에서 Rate-Monotonic 기법과 다르다.

프로세스들이 다음과 같은 주기와 수행 시간을 갖는다고 가정한다.

| 프로세스 | 주기 | 수행 시간 |
| --- | --- | --- |
| P1 | 50 | 25 |
| P2 | 100 | 35 |

EDF 스케줄링은 마감시간에 따라 우선순위를 부여 받으므로, P1이 P2 보다 먼저 실행되게 된다. 결과는 다음과 같다.

<img width="492" alt="Untitled 11" src="https://user-images.githubusercontent.com/75190035/175017593-0d1e3888-6e18-4a50-80bc-fdcd06f69739.png">

결과 이미지에서 P1, P2는 자신들의 주기에 따라 주기적으로 실행되는 것이 아닌 마감시간에 따라 우선순위를 부여받고 그 우선순위에 따라 실행을 계속하게 된다.

- Rate-Monotonic 스케줄링과 달리 EDF 스케줄링은 프로세스들이 주기적일 필요도 없고, CPU 할당 시간도 상수 값으로 정해질 필요가 없다.
- 단, 프로세스가 실행 가능해질 때 자신의 마감시간을 스케줄러에게 알려줘야 한다.
- 이론적으로 CPU 이용률이 100%가 될 수 있지만, 실제로는 문맥 교환 비용 등에 의해 불가능하다.

### 6.5 일정 비율의 몫 스케줄링_Proportionate Share Schedling

- 일정 비율의 몫 스케줄러는 모든 응용들에 T개의 시간 몫을 할당해 동작한다.

---

## 5.7 알고리즘의 평가_Algorithm Evaluation

### 7.1 결정론적 모델링_Deterministic Modeling

- 평가 방법의 한 중요한 부류로 분석적 평가(analytic evaluation)가 있다.
- 분석적 평가에서는 주어진 작업 부하에 대한 알고리즘의 성능을 평가하는 공식이나 값을 생성하기 위해 주어진 알고리즘과 시스템 부하를 이용한다.
- 분석적 평가의 한 가지 유형으로 결정론적 모델링(deterministic modeling)이 있다.

다음과 같은 프로세스들이 준비 큐에 있다고, 모든 프로세스들은 시간 0에 도착한다고 가정해 보자.

| 프로세스 | 버스트 시간(ms) |
| --- | --- |
| P1 | 10 |
| P2 | 29 |
| P3 | 3 |
| P4 | 7 |
| P5 | 12 |

이 프로세스들의 집합에 대해 선입 선처리, SJF 그리고 라운드 로빈 스케줄링 알고리즘을 고려하자. 해당 스케줄링 알고리즘에서 각각으로 수행할 것이다.

- 선입 선처리(평균 대기시간=28ms)

<img width="479" alt="Untitled 12" src="https://user-images.githubusercontent.com/75190035/175017605-da560956-3af1-4039-9a6e-53d26b8142ef.png">

- 비선점 SJF(평균 대기시간=13ms)

<img width="477" alt="Untitled 13" src="https://user-images.githubusercontent.com/75190035/175017622-e08507ce-9a2a-4260-a46a-913152103119.png">

- 라운드 로빈 알고리즘(평균 대기시간=23ms)

<img width="474" alt="Untitled 14" src="https://user-images.githubusercontent.com/75190035/175017632-ec02f3d8-b948-450e-aab7-8df5375d7f47.png">

기술된 환경에 대해(모든 프로세스들과 이들의 시간이 시간 0에 알 수 있을 때) SJF > RR > FCFS 순서로 대기시간을 최소화한다.

### 7.2 큐잉 모델_Queueing Models

- 많은 시스템에서 프로세스들은 날마다 변화하기 때문에, 결정론적 모델링을 사용할 수 있는 프로세스들의 정적인 집합이 없다. 결정할 수 있는 것은 CPU와 I/O 버스트의 분포, 프로세스들이 시스템에 도착하는 시간의 분포다.
- 이 분포들은 지수적 평균으로 기술되고 이들 두 분포로부터 알고리즘 대부분에 대한 평균 처리량, 이용률, 대기 시간 등을 게산하는 것이 가능하다.
- 큐잉 모델은 결정할 수 있는 CPU와 입출력의 분포를 사용하는 방법이다.

### 7.3 모의 실험_Simulation

- 스케줄링 알고리즘을 더 정확하게 평가하기 위해서 모의실험을 사용할 수 있다.
- 모의실험 하는 것은 컴퓨터 시스템의 모델을 프로그래밍하는 것을 포함한다.

### 7.4 구현_Implementation

- 모의실험도 정확성에 한계가 있다. 스케줄링 알고리즘을 완벽히 정확하게 평가하는 유일한 방법은 실제 코드로 작성해 운영체제에 넣고 실행해 보는 것이다.
- 이 접근 방식은 실제 운영 환경하에서의 평가를 위해 실제 시스템에 실제 알고리즘을 삽입하는 것이다.

---

> 참고
> 
> - 책
> 
> [⌜Operating System Concepts 10th - Abraham Silberschatz, Peter B. Galvin, Greg Gagne⌟](http://www.yes24.com/Product/Goods/78225791)
> 
> - 블로그
> 
> [https://will-behappy.tistory.com/22?category=808600](https://will-behappy.tistory.com/22?category=808600)
> 
> [https://suhwanc.tistory.com/179?category=879656](https://suhwanc.tistory.com/179?category=879656)
>
